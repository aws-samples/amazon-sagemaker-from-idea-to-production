{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e704ecf-a79c-4599-95c3-53fa7db61d17",
   "metadata": {},
   "source": [
    "# Assignment 6: Implement data and model quality monitoring\n",
    "In this assignment you use [Amazon SageMaker model monitor](https://aws.amazon.com/sagemaker/model-monitor/) to implement a continious data quality monitoring for a real-time inference endpoint.\n",
    "\n",
    "Refer to the notebook [`06-monitoring.ipynb`](../06-monitoring.ipynb) for code snippets and a general guidance for the exercises in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686992b-b98b-4458-9419-df81c7eb452d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da22b3-7897-4180-859a-87707d613f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonlines tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa988d-6b9d-4b3d-9f0f-5d23db3e600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import sagemaker \n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "from tqdm import trange\n",
    "from sagemaker.predictor import Predictor\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.model_monitor import (\n",
    "    DefaultModelMonitor,\n",
    "    DataCaptureConfig,\n",
    "    CronExpressionGenerator,\n",
    "    ModelQualityMonitor,\n",
    "    EndpointInput,\n",
    ")\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from utils.monitoring_utils import run_model_monitor_job\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ef793-492c-43c9-960e-7f1fa73ab19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")\n",
    "s3 = boto3.client(\"s3\")\n",
    "session = sagemaker.Session()\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86c416-de73-46f5-a53d-f47eb283e34a",
   "metadata": {},
   "source": [
    "## Exercise 1: Check data capture configuration\n",
    "Use any one of the existing inference endpoints you deployed in the previous notebook. The data capture is configured at 100% of the incoming data for the staging and at 80% for the production endpoint. Verify this configuration in **Endpoint details** view in Studio UX.\n",
    "\n",
    "![](../img/endpoints.png)\n",
    "\n",
    "![](../img/endpoint-details-data-capture.png)\n",
    "\n",
    "You can also use `boto3` to describe an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4a0cb-69a2-46c2-9fb5-ea4407499c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details of the endpoint\n",
    "# ep_name = \n",
    "# sm.describe_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d10770-52cb-47b4-acd5-52176599ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the S3 url where the capture data files are stored\n",
    "# data_capture_uri = sm.describe_endpoint(EndpointName=ep_name)['DataCaptureConfig']['DestinationS3Uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccd1f5-0f97-4b0d-b9e5-e95cf7e7a5be",
   "metadata": {},
   "source": [
    "## Exercise 2: Generate and view captured data\n",
    "In this exercise you send data to the inference endpoint to generate captured data. Use SageMaker Python SDK class [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor) to interact with the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939bfaf-e030-4b4e-be7d-7269bfa23069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictor from the endpoint name\n",
    "# endpoint_name = \n",
    "# predictor = Predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6afe37-5c33-4b9e-8d49-807a9a1f8c76",
   "metadata": {},
   "source": [
    "For test data you can use the test dataset in the `tmp` folder created in the `02-sagemaker-containers.ipynb` notebook. If you don't have the test dataset you can generate it by running the model building pipeline and dowloading the test dataset from the Amazon S3 bucket to the `tmp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d37dcb-9030-409f-aeb4-d1124b4319d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# test_x = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a2b8e-b806-4739-b412-b0fd92f9fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send data to the endpoint\n",
    "def generate_endpoint_traffic(predictor, data):\n",
    "    l = len(data)\n",
    "    print(f\"Sending {l} vectors to the endpoint\")\n",
    "    for i in trange(l):\n",
    "        predictions = np.array(predictor.predict(data.iloc[i].values), dtype=float).squeeze()\n",
    "        time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf29e7-480d-4103-b19d-666459b2f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate endpoint traffic\n",
    "# generate_endpoint_traffic(predictor, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69ca79-19eb-43bd-9204-2b3360b15fdd",
   "metadata": {},
   "source": [
    "Wait several minutes for files with captured data to appear in the Amazon S3 bucket. \n",
    "\n",
    "Each inference request is captured in one line in the `jsonl` file. The line contains both the input and output merged together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a064f-9733-4925-8623-badd3744b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files in the capture S3 prefix\n",
    "# !aws s3 ls {data_capture_uri} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd1a1a-9ff4-4a25-8f70-f0ee0700ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the last captured datset to Studio's EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2acbf2-d89a-4fc7-96c1-33dbe060feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print jsonl objects "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24644e1-6533-40d6-8b81-db97149bd255",
   "metadata": {},
   "source": [
    "## Exercise 3: Run baseline data profiling\n",
    "To enable data monitoring you must first create baseline statistics and constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd5dc3-a4a6-47dd-a62d-e28c914e7ef9",
   "metadata": {},
   "source": [
    "### Create a baselining job\n",
    "To profile the data and create a baseline, use the baseline dataset `baseline.csv` which is produced by the model building pipeline. If you don't have the baseline dataset, execute the pipeline. Refer to the notebook `03-assignment-sagemaker-pipeline.ipynb` to get the S3 path to the baseline dataset.\n",
    "\n",
    "Use [DefaultModelMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor) to interact with SageMaker model monitor functionality. To create a baseline call [`suggest_baseline`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor.suggest_baseline) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be548daf-7b72-44f4-b2d4-0131afd913fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a baseline dataset under the specified S3 url\n",
    "# !aws s3 ls {baseline_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4473c-a461-4da2-b790-a8039d3e2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Amazon S3 paths corresponding to your environment\n",
    "baseline_results_s3_url = \"<where the baseline results will be stored>\"\n",
    "reports_s3_url = \"<where the monitoring job reports will be stored>\"\n",
    "baseline_dataset_uri = \"<points to the baseline dataset including file name>\"\n",
    "baseline_job_name = \"<job name so you can recognize it in the SageMaker console>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ce707-bc7b-4476-af07-f3eaea3c0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DefaultModelMonitor\n",
    "# data_monitor = DefaultModelMonitor()\n",
    "\n",
    "# Run profiling job\n",
    "# data_monitor.suggest_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b814a1b-1b72-474a-a4bd-d2c4bf55f8ec",
   "metadata": {},
   "source": [
    "Wait until the profiling job completes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787c51d-57aa-4af9-b02f-ea20bf1a637b",
   "metadata": {},
   "source": [
    "### See the generated statistics and constraints\n",
    "The baselining jobs saves the baseline statistics to the `statistics.json` file and the suggested baseline constraints to the `constraints.json` file in the location you specify as the `output_s3_uri` parameter.\n",
    "\n",
    "You can access statistics and constraints also via [`baseline_statistics()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.BaseliningJob.baseline_statistics) and [`suggested_constraints()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.BaseliningJob.suggested_constraints) methods of the `DefaultModelMonitor.latest_baselining_job` attribute.\n",
    "\n",
    "Explore what statistics and constraints the profiling job generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94773df2-536a-45bd-ac83-5b6866e8dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 ls {baseline_results_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698b6dc-f597-4f2e-bc74-82c0631e4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore generated constraints and statistics for the baseline dataset\n",
    "# baseline_job = data_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27528085-fa11-4bdd-baf8-91a230693668",
   "metadata": {},
   "source": [
    "You can also load a normalized JSON from the `statistics.json` and `constraints.json` into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e3a8d-21f2-46c4-9493-12d2b18f1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ece2bb-1f3b-478d-9f82-db2a29492d3b",
   "metadata": {},
   "source": [
    "## Exercise 4: Monitor data quality\n",
    "After you have created the baseline constraints and statistics you can now validate if incoming data has the same statistical distribution and complies with all configured constraints.\n",
    "\n",
    "You can either use scheduled executions of the Model Monitor analyser or run the analyser manually as a SageMaker processing job. \n",
    "\n",
    "The Model Monitor compares the captured data with the baseline periodically based on a configured [monitoring schedule](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-data-monitor.html).\n",
    "\n",
    "If you run the analyzer manually, you provide the baseline statistics and constraints as SageMaker processing job parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f0170-6146-466d-b310-9473ff9ca7ef",
   "metadata": {},
   "source": [
    "### Create a monitoring schedule\n",
    "To create a monitoring schedule use [`create_monitoring_schedule()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor.create_monitoring_schedule) method of the `DefaultModelMonitor` class. Use [`CronExpressionGenerator`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.cron_expression_generator.CronExpressionGenerator) class to generate a cron expression string.\n",
    "\n",
    "When you created a monitoring baseline, you used the baseline dataset with all features but without the label. The Model Monitor by default concatenates model's input and output, resulting in a dataset which contains all features plus the label. If you don't preprocess records before passing them to the Model Monitor analyzer, the number of columns in the baseline dataset won't match the number of columns in the record, and Model Monitor will report a `extra_column_check` violation. To avoid this situation, you need either to include the label column in the baselining or remove model output from the monitored records. You can use a [custom record preprocessing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html) script that returns only input data without the label. See the notebook [`06-monitoring.ipynb`](../06-monitoring.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4ccc8-6c98-41b9-a4ce-8255214878a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the custom record preprocessing script\n",
    "!pygmentize ../record_preprocessor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0c0fc-b297-4f5d-9b31-55c75b82b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the record preprocessing script to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d923917-a56e-4ee8-ae4d-5c439434b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set monitoring schedule name and create monitoring schedule\n",
    "# mon_schedule_name = # use a unique name for your monitoring schedule\n",
    "# data_monitor.create_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55eded-26fc-4b3b-b954-2f1d572ba310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monitoring schedule details\n",
    "## data_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c120b4-7704-4013-84ed-dbeed2608f65",
   "metadata": {},
   "source": [
    "### Generate compliant traffic\n",
    "Generate some endpoint traffic using `generate_endpoint_traffic` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74903da-f6c5-4f7a-a9c9-a4e160b86472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_endpoint_traffic(predictor, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf40377-d8cb-4a7d-8213-0239ab4ba266",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See the captured data under {data_capture_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05527edb-8afe-445b-a1ab-56eb4a521483",
   "metadata": {},
   "source": [
    "### Launch a manual monitoring job\n",
    "If you don't want to wait until a configured scheduled Model Monitor run launched, you can run analyser manually using a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) and a SageMaker [processing job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html).\n",
    "\n",
    "See the source code in this [repository](https://github.com/aws-samples/reinvent2019-aim362-sagemaker-debugger-model-monitor/tree/master/02_deploy_and_monitor). You have also the copy of the [helper function](../utils/monitoring_utils.py) in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d5d04-606c-4021-9aa4-9279ef129c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ../utils/monitoring_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5a33a-f9c2-48eb-a359-3afd16b65506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters and run a Model Analyzer processing job\n",
    "# utils.monitoring_utils.run_model_monitor_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a210a5-dee3-40da-94ba-2204d24ab9b4",
   "metadata": {},
   "source": [
    "### Explore the monitoring job output\n",
    "Since you run the analyser as a SageMaker processing job, you can access all job details via standard API. For example, you can retrieve an S3 uri for the job output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9b957-e683-425e-8de3-36ec968daeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_job_name = sm.list_processing_jobs(\n",
    "    NameContains = 'sagemaker-model-monitor-analyzer',\n",
    "    SortOrder='Descending',\n",
    "    MaxResults=2\n",
    ")['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "\n",
    "analyzer_job_info = sm.describe_processing_job(\n",
    "    ProcessingJobName=analyzer_job_name\n",
    ")\n",
    "\n",
    "analyzer_job_output_s3_url = analyzer_job_info['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "\n",
    "print(analyzer_job_output_s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5dade-22df-48d6-9076-3d1a6e11173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the generated analyzer output\n",
    "!aws s3 ls {analyzer_job_output_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e819b9c-4ab1-4c69-a19d-9c32d639ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files as Pandas DataFrame and explore generated statistics, constraints, and violations\n",
    "# statistics = # load file\n",
    "# constraints = # load file\n",
    "# violations = pd.read_json(f\"{analyzer_job_output_s3_url}/constraint_violations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b42d7-ce4d-42ef-bcf5-a7587741ba3b",
   "metadata": {},
   "source": [
    "### Generate non-compliant traffic\n",
    "Now generate some non-compliant traffic to your real-time inference endpoint and run the Model Monitor analyzer again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c0716-2eb0-40de-8f09-26ee7a6991c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous data capture files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95caf4-3a00-4f55-a74e-b017e4a1a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or inject non-compliant data into requests\n",
    "# Prepare a non-compliant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61379c46-8029-4b44-8b8b-9931b660c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traffic using non-compliant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f8c95-baec-4400-811d-f1cf91dc035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a Model Monitor analyzer processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00915e37-a5be-4907-a8e6-7239ed3521ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the analyzer report\n",
    "# use the same code as in the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a3b59-9d92-441c-b759-9b51dbaf2ba6",
   "metadata": {},
   "source": [
    "### Work with scheduled executions and monitoring reports\n",
    "Model Monitor scheduled executions offer a more abstract way of working with analyzer runs and monitoring reports. Instead of using SageMaker processing job API, you can use Python SDK [`ModelMonitor`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelMonitor)-derived classed to access all scheduled executions, execution details, generated statistics, constraints, and violations for each execution.\n",
    "\n",
    "The scheduled executions automatically process only the newest captured data since the last Model Monitor analyzer run. You can also [visualize data quality reports](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html) in SageMaker Studio.\n",
    "\n",
    "Refer to [SageMaker Model Monitor development guide](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-violations.html) for result interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199a84b2-9a20-4905-9f2c-769af236f613",
   "metadata": {},
   "source": [
    "#### List executions of a scheduled Model Monitoring job\n",
    "Use [`list_executions()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelMonitor.list_executions) of the `ModelMonitor` Python SDK class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11088d9-5a7b-408b-98e2-c97b27668632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all executions\n",
    "# Get the latest execution details\n",
    "# Get the execution output S3 url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe590744-71d8-45fa-a4e3-40b5e5d467e7",
   "metadata": {},
   "source": [
    "#### Get the latest execution statistics and constraints\n",
    "You can access the latest output with this code:\n",
    "```\n",
    "my_executions = my_monitor.list_executions()\n",
    "lastest_execution_statistics = my_executions[-1].statistics()\n",
    "lastest_execution_violations = my_executions[-1].constraint_violations()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9e158-f456-47ed-b7c5-ab5404120190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to print the latest statistics and constraint violations\n",
    "# Hint: use Pandas DataFrame to visualize the reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad819e7a-3023-4c5f-9a48-a2becf0feb6e",
   "metadata": {},
   "source": [
    "#### See the baseline and the latest data profiling statistics\n",
    "Use [`latest_monitoring_statistics()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelMonitor.latest_monitoring_statistics) and [`baseline_statistics()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelMonitor.baseline_statistics) methods to load monitoring output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110275d-a21b-49c7-a811-7cbb4e8682df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here to see the latest monitoring statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7e4e9-f0fd-483c-8932-ba91a1519344",
   "metadata": {},
   "source": [
    "#### See a violation report\n",
    "Use [`latest_monitoring_constraint_violations()`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelMonitor.latest_monitoring_constraint_violations) to return the latest constraint violation report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745c7bf-f4a0-4741-8a2a-ca55f0889751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest constraint violations report into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d010840-0c1e-417e-a027-33ae692b10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data monitoring results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d8c50-a452-44fd-9f33-72a6e2e7fa55",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f638da7-d101-46ce-9fb6-287a199c2f03",
   "metadata": {},
   "source": [
    "## Exercise 5: Monitor model quality\n",
    "Implementing model quality monitoring follows the same steps as the data quality monitoring with addition of ground truth data ingestion.\n",
    "\n",
    "See the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html) documentation on model quality monitoring and **Part 2: Monitor model quality** of the [step 6](../06-monitoring.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4d803-edda-41b3-92a5-7bcee0341524",
   "metadata": {},
   "source": [
    "### Create a model quality monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457813f-d5cd-4c29-836c-d39c22f0a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_monitor = ModelQualityMonitor(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99f51e-3655-4fb7-8e55-2f95394f8a2a",
   "metadata": {},
   "source": [
    "### Run a model quality baseline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8c7f0-3267-43d9-8dcf-c3ad05291a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_baseline_job = model_monitor.suggest_baseline(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3487255-2576-4dba-83a7-06de46a0dcc6",
   "metadata": {},
   "source": [
    "### Inspect the generated baseline reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efac44-4e28-49fd-8950-559844f2c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_model_baseline_job = model_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db529b5-85a5-4214-91b0-df7b28268084",
   "metadata": {},
   "source": [
    "### Generate endpoint traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797c06f-1e24-4493-b382-0cf4d4a6698c",
   "metadata": {},
   "source": [
    "### Ingest ground truth data\n",
    "Remember to correlate the ground truth labels with the inference input via `EventId` identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf444aa-8b50-4e2d-a3c4-df61d9bbb6b8",
   "metadata": {},
   "source": [
    "### Create a model monitoring schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c00aa-026c-4d8e-aebd-e1028620ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_input = EndpointInput(...)\n",
    "# model_monitor.create_monitoring_schedule(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ddc04-d530-45cc-96e6-eed1ab28b45b",
   "metadata": {},
   "source": [
    "### Inspect model monitor executions and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f4967-a645-4392-b276-170ff36e73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mon_executions = model_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1094a-07e9-4b55-b442-b8fdf7b715ee",
   "metadata": {},
   "source": [
    "## Continue with the clean-up\n",
    "After you finished with the assignments and experiments, you must clean-up all created resources.\n",
    "\n",
    "Navigate to the [clean-up](../99-clean-up.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37851f9f-7384-4211-83ad-a9790eabc4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
