{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0551f521-eaea-4e5c-a9a9-60a93aaa018e",
   "metadata": {},
   "source": [
    "# Step 6: Add data monitoring\n",
    "After executing six previous notebooks, you have a production-ready solution with automated model building and model deployment CI/CD pipelines.\n",
    "This notebook adds continuous monitoring of the data quality in real-time. [Amazon SageMaker model monitor](https://aws.amazon.com/sagemaker/model-monitor/) enables you to set up an automated alert triggering system when there are deviations in the data and model quality, such as data drift and anomalies.\n",
    "\n",
    "\n",
    "\n",
    "![](img/six-steps-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2681315-b19c-4e97-a49e-21f04efb6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "import json\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.predictor import Predictor\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import CronExpressionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8d993-1c33-40ad-96ee-7340edadcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fb029-39b2-48ee-a3d6-38f1a42f25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae4a24-1294-4bda-8f68-4e811025932d",
   "metadata": {},
   "source": [
    "## How model monitor works\n",
    "Amazon SageMaker Model Monitor automatically monitors ML models in production and notifies you when quality issues arise. Model Monitor uses rules to detect drift in your models and data and alerts you when it happens. The following figure shows how this process works.\n",
    "\n",
    "![](img/model-monitor.png)\n",
    "\n",
    "The process for setting up the data monitoring:\n",
    "1. Enable the endpoint to capture data from incoming requests to a trained ML model and the resulting model predictions\n",
    "2. Create a baseline from the dataset that was used to train the model. The baseline computes metrics and suggests constraints for the metrics. Real-time predictions from your model are compared to the constraints, and are reported as violations if they are outside the constrained values\n",
    "3. Create a monitoring schedule specifying what data to collect, how often to collect it, how to analyze it, and which reports to produce\n",
    "4. Inspect the reports, which compare the latest data with the baseline, and watch for any violations reported and for metrics and notifications from Amazon CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f977d10-057f-4d9f-85ba-17b5dd7ebff6",
   "metadata": {},
   "source": [
    "## Real-time inference data capture from a SageMaker endpoint\n",
    "To work with the model monitor, use the existing endpoints deployed by the deployment pipeline in the step 5 notebook.\n",
    "\n",
    "The model deployment MLOps project implemented in the step 5 notebook contains a data capture configuration for the deployed endpoints. If you clone the project's code repository to the Studio file system, you can see the project files.\n",
    "\n",
    "The CloudFormation deployment template `endpoint-config-template.yml` enables data capture for the endpoint configuration:\n",
    "```yaml\n",
    "EndpointConfig:\n",
    "    Type: AWS::SageMaker::EndpointConfig\n",
    "    Properties:\n",
    "      ProductionVariants:\n",
    "        - InitialInstanceCount: !Ref EndpointInstanceCount\n",
    "          InitialVariantWeight: 1.0\n",
    "          InstanceType: !Ref EndpointInstanceType\n",
    "          ModelName: !GetAtt Model.ModelName\n",
    "          VariantName: AllTraffic\n",
    "      DataCaptureConfig:\n",
    "          EnableCapture: !Ref EnableDataCapture \n",
    "          InitialSamplingPercentage: !Ref SamplingPercentage\n",
    "          DestinationS3Uri: !Ref DataCaptureUploadPath\n",
    "          CaptureOptions:\n",
    "            - CaptureMode: Input\n",
    "            - CaptureMode: Output\n",
    "          CaptureContentTypeHeader:\n",
    "            CsvContentTypes:\n",
    "              - \"text/csv\"\n",
    "```\n",
    "\n",
    "The configuration files `prod-config.json` and `staging-config.json` provide the actual values for `EnableCapture`, `InitialSamplingPercentage`, and `DestinationS3Uri`:\n",
    "```json\n",
    "{\n",
    "  \"Parameters\": {\n",
    "    \"StageName\": \"prod\",\n",
    "    \"EndpointInstanceCount\": \"1\",\n",
    "    \"EndpointInstanceType\": \"ml.m5.large\",\n",
    "    \"SamplingPercentage\": \"80\",\n",
    "    \"EnableDataCapture\": \"true\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's check the endpoint configuration and see how data capture is confgured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bcd2e-95f9-4dfd-9830-a48b579c7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in sm.list_endpoints(StatusEquals=\"InService\")[\"Endpoints\"]:\n",
    "    print(f\"Data capture configuration for {ep['EndpointName']}:\")\n",
    "    print(f\"{json.dumps(sm.describe_endpoint(EndpointName=ep['EndpointName'])['DataCaptureConfig'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891b9fe-37a3-44fa-a1d6-2fe94262410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configuration for a specific endpoint name\n",
    "endpoint_name = \"step5-deploy-model-prod\"\n",
    "data_capture_uri = sm.describe_endpoint(EndpointName=endpoint_name)['DataCaptureConfig']['DestinationS3Uri']\n",
    "data_capture_bucket = data_capture_uri.split('/')[2]\n",
    "data_capture_prefix = '/'.join(data_capture_uri.split('/')[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e011d-ba01-43c8-8af9-959bb7835574",
   "metadata": {},
   "source": [
    "### Generate captured data\n",
    "You must send some data to an endpoint for inference to generate data capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0fd2a-65e6-48d2-ab50-2e6cf8597f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {data_capture_uri} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58229914-7fa6-4d5c-841b-2bbc32c6add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652224c3-4121-41c1-9494-f4d8a287f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"tmp/test_x.csv\", names=[f'{i}' for i in range(59)])\n",
    "test_y = pd.read_csv(\"tmp/test_y.csv\", names=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7da46e-d957-4351-a804-2724cd0c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_endpoint_traffic(predictor, repeats=10):\n",
    "    for _ in range(0,repeats):\n",
    "        print(\"sending inference data to the endpoint\")\n",
    "        predictions = np.array(predictor.predict(test_x.values), dtype=float).squeeze()\n",
    "        print(predictions)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cdd96-de42-4b63-9925-415097ecc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_endpoint_traffic(predictor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ca97e-2129-4371-9695-c08d3e46f11b",
   "metadata": {},
   "source": [
    "### View captured data\n",
    "Now list the data capture files stored in Amazon S3. The data is stored as `jsonl` an Amazon S3 path format is `s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6a4c5-09ae-464e-a24a-9c474e6ae10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "\n",
    "capture_files = [\n",
    "    capture_file.get(\"Key\") \n",
    "    for capture_file in s3_client.list_objects(Bucket=data_capture_bucket, Prefix=data_capture_prefix).get(\"Contents\")\n",
    "]\n",
    "print(\"Found data capture files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ba1b4-8e39-4b1b-8f17-3253e6cb0a9b",
   "metadata": {},
   "source": [
    "Each inference request is captured in one line in the `jsonl` file. The line contains both the input and output merged together. In the example, you provided the ContentType as `text/csv` which is reflected in the `observedContentType` value. Also, you expose the encoding that you used to encode the input and output payloads in the capture format with the encoding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d889d7-f212-4414-9c08-b15d14754048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=data_capture_bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada3476-3067-47e8-bcc1-f515972048c2",
   "metadata": {},
   "source": [
    "## Model monitor - monitor data quality\n",
    "In this example you learn how to setup data quality monitoring.\n",
    "\n",
    "To enable inference data quality monitoring and evaluation you must:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-create-baseline.html) with which you compare the realtime traffic\n",
    "1. Once a baseline is ready, [schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-scheduling.html) to continously evaluate and compare against the baseline\n",
    "1. [Interpret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html) of monitoring jobs\n",
    "1. [Integrate data quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-cloudwatch.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84268bba-f44e-4cb4-a53f-67251253c1a4",
   "metadata": {},
   "source": [
    "### Create a baselineing job with training dataset\n",
    "The training dataset with which you trained the model is usually a good baseline dataset. Note that the training dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the training dataset you can ask Amazon SageMaker to suggest a set of baseline _constraints_ and generate descriptive _statistics_ to explore the data. Model Monitor provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) that provides the ability to suggest the constraints automatically for CSV and flat JSON input. This `sagemaker-model-monitor-analyzer` container also provides you with a range of model monitoring capabilities, including constraint validation against a baseline, and emitting Amazon CloudWatch metrics. This container is based on Spark and is built with [Deequ](https://github.com/awslabs/deequ). All column names in your baseline dataset must be compliant with Spark. For column names, use only lowercase characters, and _ as the only special character.\n",
    "\n",
    "Use the training dataset you created in the step 2 notebook data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaac6de-b3a9-4f4d-b6e2-2f2a66b86a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {train_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632362d5-c4e0-4bf5-bca4-b4da6ad34377",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_s3_url = f\"{baseline_s3_url}/results\"\n",
    "reports_s3_url = f\"{baseline_s3_url}/reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774449c4-e71a-4206-9d03-09821f6e1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dataset_uri = f\"{train_s3_url}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b765256-592c-4b4e-bc7e-f7176aede653",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job_name = f\"from-idea-to-prod-processing-baselining-{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49b158-9859-4053-8ec9-8f99577ed07e",
   "metadata": {},
   "source": [
    "Start a SageMaker projcessing job on the baseline data to profile data and suggest constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443d53d-00e9-4320-9c72-1751fe796778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monitor = DefaultModelMonitor(\n",
    "    role=sm_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "data_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_s3_url,\n",
    "    wait=True,\n",
    "    logs=False,\n",
    "    job_name=baseline_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9063-5fb6-4bda-86c1-d33b2b0ca10b",
   "metadata": {},
   "source": [
    "### See the generated statistics and constraints\n",
    "The baselining jobs saves the baseline statistics to the `statistics.json` file and the suggested baseline constraints to the `constraints.json` file in the location you specify with `output_s3_uri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77ab21-f595-417e-a880-a3cb73be87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {baseline_results_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f849c-8ca0-4c7f-a3a4-eac7b7553b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = data_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb5f66-da5c-477f-b66a-3997713404bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89bdfa-87a8-4a23-a299-0a303bbd9bcd",
   "metadata": {},
   "source": [
    "### Create a monitoring schedule\n",
    "With a monitoring schedule, SageMaker launches processing jobs at a specified frequency to analyze the data collected during a given period. SageMaker provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) for performing analysis on tabular datasets. In the processing job, SageMaker compares the dataset for the current analysis with the baseline statistics and constraints and generates a violations report. In addition, CloudWatch metrics are emitted for each data feature under analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179ca01-f71e-4544-9ebb-daa61b74d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_schedule_name = \"from-idea-to-prod-monitor-schedule-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "\n",
    "data_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    # record_preprocessor_script=pre_processor_script,\n",
    "    # post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=reports_s3_url,\n",
    "    statistics=data_monitor.baseline_statistics(),\n",
    "    constraints=data_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a44fa-2ebf-4cf4-b34f-f72aeba5837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_endpoint_traffic(predictor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98be4d2-0bcf-476a-a9e5-f710b2ecb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_schedule_result = data_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e46a76-d556-4d75-8b38-454fba95d419",
   "metadata": {},
   "source": [
    "### List schedule executions\n",
    "Youe created a hourly schedule above that begins executions on the hour (plus 0-20 min buffer. You will have to wait till the clock hit the hour. You can also change the schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6b282-0949-441c-b0c7-e55ef9ff7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_executions = data_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301094d-8039-42a0-b17d-5539d26a7c87",
   "metadata": {},
   "source": [
    "### View a monitoring job execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d60781-821c-43c2-963b-9aab79c23e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(mon_executions):\n",
    "    latest_execution = mon_executions[-1]  # get the latest execution\n",
    "    latest_execution.wait(logs=False)\n",
    "\n",
    "    print(\"Latest execution status: {}\".format(latest_execution.describe()[\"ProcessingJobStatus\"]))\n",
    "    print(\"Latest execution result: {}\".format(latest_execution.describe()[\"ExitMessage\"]))\n",
    "\n",
    "    latest_job = latest_execution.describe()\n",
    "    if latest_job[\"ProcessingJobStatus\"] != \"Completed\":\n",
    "        print(\"No completed executions to inspect further\")\n",
    "    else:\n",
    "        report_uri = latest_execution.output.destination\n",
    "        print(f\"Report Uri: {report_uri}\")\n",
    "else:\n",
    "    print(\"No executions found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1d859-3753-49ea-ad78-d18f0b5a8bec",
   "metadata": {},
   "source": [
    "### View a violation report\n",
    "Model monitor outputs any violations compared to the baseline to a violation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863de7d-22fc-467e-958b-d76dbb3e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {reports_s3_url}/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31de1c-77b3-4992-a2ab-237367c96340",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = data_monitor.latest_monitoring_constraint_violations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9773b1-0f77-48f7-8090-7dcacfc0f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if violations:\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    constraints_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "    constraints_df.head(10)\n",
    "else:\n",
    "    print(\"No violations report found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e698a8-68ee-493f-bf1b-ffddea569762",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2669f3-a09b-4ca8-9a17-a706239f16c4",
   "metadata": {},
   "source": [
    "## Model monitor - monitor model quality\n",
    "Model quality monitoring jobs monitor the performance of a model by comparing the predictions that the model makes with the actual ground truth labels that the model attempts to predict. To do this, model quality monitoring merges data that is captured from real-time inference with actual labels that you store in an Amazon S3 bucket, and then compares the predictions with the actual labels.\n",
    "\n",
    "Model quality monitoring follows the same steps as data quality monitoring, but adds the additional step of merging the actual labels from Amazon S3 with the predictions captured from the real-time inference endpoint.\n",
    "\n",
    "To monitor model quality, follow these steps:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-baseline.html). A baseline job compares predictions from the model with ground truth labels in a baseline dataset\n",
    "1. [Schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-schedule.html)\n",
    "1. [Ingest ground truth labels](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) that model monitor merges with captured prediction data from real-time inference endpoint\n",
    "1. [Intepret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html)\n",
    "1. [Integrate model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-cw.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59071f22-f07e-446e-834e-f7bc2d44f40b",
   "metadata": {},
   "source": [
    "## Additional monitoring\n",
    "Additionally to data and model quality monitoring with Model Monitor, you can use Amazon SageMaker Clarify to:\n",
    "- [Monitor bias drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html)\n",
    "- [Monitor feature attribution drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html)\n",
    "\n",
    "Refer to a sample notebook [Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html) for a hands-on example and more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057c12f-1aae-4087-8930-4150543ff38a",
   "metadata": {},
   "source": [
    "## Use SageMaker Studio for data and model monitoring\n",
    "You can use Studio UX to enable and configure data and model monitoring and to visualize results. You can view the details of any monitoring job run, and you can create charts that show the baseline and captured values for any metric that the monitoring job calculates.\n",
    "\n",
    "Navigate to **SageMaker resources** to the left side bar and choose **Endpoints** in the drop-down menu. Double-click on an endpoint for which you would like to configure the model monitoring:\n",
    "\n",
    "<img src=\"img/endpoints.png\" width=\"400\"/>\n",
    "\n",
    "In the displayed **Endpoint details** tab you can configure data and model monitoring:\n",
    "\n",
    "![](img/model-monitoring-ux.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed36be-5547-481a-90c4-3d8647db0957",
   "metadata": {},
   "source": [
    "## Clean-up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e36c7-d86d-4b6a-ae06-6884fbfe3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monitor.stop_monitoring_schedule()\n",
    "data_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fc9ec-caa3-4adf-9b9a-66bf6ba3ec71",
   "metadata": {},
   "source": [
    "### Final clean-up\n",
    "This is the last notebook in this workshop. If you are finished with exploration, to avoid charges on your AWS account, run the [clean-up notebook](99-clean-up.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea675fa-2d8f-4b15-b9cd-91104a96edee",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add [visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html) for model monitoring reports\n",
    "- Add data baselining, explainability report generation, and bias report to the model building pipeline\n",
    "- Implement [model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html)\n",
    "- Try different inference options such as [serverless](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html) or [asynchronous](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html) inference\n",
    "- Address security considerations for your ML environment and solutions. Start with the developer guide [Security in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- Implement [deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html) to control how to update your models in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9b6df-94d1-49ee-a21b-42b153d3fe4c",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)\n",
    "- [Monitor data quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html)\n",
    "- [Model Monitor visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html)\n",
    "- [Monitor Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html)\n",
    "- [Monitoring a Model in Production](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-model-monitor.html)\n",
    "- [Security in Amazon SageMakerv](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- [Deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54a7b1-0e4a-424c-9283-07c62c1a4e2a",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc068d-e111-46db-aaef-01fc30fa5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5fa65-6e71-4e91-9449-0ea57a5261c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
