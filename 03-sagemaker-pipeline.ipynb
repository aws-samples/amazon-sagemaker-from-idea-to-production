{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "575c15ae-ffe0-4d93-84d8-bf96278c0372",
   "metadata": {},
   "source": [
    "# Step 3: Add an ML pipeline\n",
    "\n",
    "In this step you automate our end-to-end ML workflow using [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) and [Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html). You make feature engineering re-usable, repeatable, and scaleable using [Amazon SageMaker Feature Store](https://aws.amazon.com/sagemaker/feature-store/).\n",
    "\n",
    "![](img/six-steps-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca42d3f-7231-44cc-83f4-a54c6a7995f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import pathlib\n",
    "import io\n",
    "import sagemaker\n",
    "from time import gmtime, strftime, sleep\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput, \n",
    "    ProcessingOutput, \n",
    "    ScriptProcessor\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    TrainingStep, \n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig, \n",
    "    ClarifyCheckStep, \n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThan,\n",
    "    ConditionGreaterThanOrEqualTo\n",
    ")\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import (\n",
    "    Join,\n",
    "    JsonGet\n",
    ")\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource, \n",
    "    ModelMetrics, \n",
    "    FileSource\n",
    ")\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ac5a8-2730-45fd-8bed-1559c422748c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "defd6d8b-a230-4bf8-a575-2c6dcff55615",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b507e-f512-49c9-9f59-6477133bd118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set names of pipeline objects\n",
    "project = \"from-idea-to-prod\"\n",
    "\n",
    "pipeline_name = f\"{project}-pipeline\"\n",
    "pipeline_model_name = f\"{project}-model-xgb\"\n",
    "model_package_group_name = f\"{project}-model-group\"\n",
    "endpoint_config_name = f\"{project}-endpoint-config\"\n",
    "endpoint_name = f\"{project}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947da3b-e046-4dea-9897-1717c5bbc3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set instance types and counts\n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9be066-8452-4058-b50e-e3027cb466b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set S3 urls for processed data\n",
    "train_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/train\"\n",
    "validation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/validation\"\n",
    "test_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/test\"\n",
    "baseline_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/baseline\"\n",
    "\n",
    "evaluation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/evaluation\"\n",
    "prediction_baseline_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/prediction_baseline\"\n",
    "\n",
    "output_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d649cf-b64c-4978-b3f5-cf767b7f1870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store train_s3_url\n",
    "%store validation_s3_url\n",
    "%store test_s3_url\n",
    "%store baseline_s3_url\n",
    "%store model_package_group_name\n",
    "%store evaluation_s3_url\n",
    "%store prediction_baseline_s3_url\n",
    "%store output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b75414-0239-4682-a435-22d646bb16cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Train S3 url: {train_s3_url}\")\n",
    "print(f\"Validation S3 url: {validation_s3_url}\")\n",
    "print(f\"Test S3 url: {test_s3_url}\")\n",
    "print(f\"Data baseline S3 url: {baseline_s3_url}\")\n",
    "print(f\"Evaluation metrics S3 url: {evaluation_s3_url}\")\n",
    "print(f\"Model prediction baseline S3 url: {prediction_baseline_s3_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2b376-7e6e-448e-b297-d2fad7d4f8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    input_s3_url\n",
    "except NameError:      \n",
    "    #Â If input_s3_url is not defined, upload the dataset to S3 and store the path\n",
    "    input_s3_url = sagemaker.Session().upload_data(\n",
    "        path=\"data/bank-additional/bank-additional-full.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{bucket_prefix}/input\"\n",
    "    )\n",
    "    print(f\"Upload the dataset to {input_s3_url}\")\n",
    "\n",
    "    %store input_s3_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "626ea883-3bd9-4947-a0c8-7c3a80c1bbca",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa00ef9a-a6fe-4415-9847-bcfa97f32c44",
   "metadata": {},
   "source": [
    "### Setup pipeline parameters\n",
    "SageMaker Pipelines supports [parameterization](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html), which allows you to specify input parameters at runtime without changing your pipeline code. You can use the parameter classes available under the [`sagemaker.workflow.parameters`](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#parameters) module.\n",
    "Parameters have a default value, which you can override by specifying parameter values when starting a pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f370b6-1ee3-4bc6-ae85-5eef37878196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set model approval param\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "#Â Minimal threshold for model performance on the test dataset\n",
    "test_score_threshold_param = ParameterFloat(\n",
    "    name=\"TestScoreThreshold\", \n",
    "    default_value=0.75\n",
    ")\n",
    "\n",
    "# Set S3 url for input dataset\n",
    "input_s3_url_param = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=input_s3_url,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "869c3182-d926-4aa5-b8c0-23d7c782f116",
   "metadata": {},
   "source": [
    "### Build the pipeline steps\n",
    "You include the following steps in the pipeline:\n",
    "1. **Data processing step**: runs a SageMaker processing job for feature engineering and dataset split\n",
    "1. **Training step**: runs a SageMaker training job using XGBoost algorithm\n",
    "1. **Evaluation step**: evaluate the performance of the trained model\n",
    "1. **Condition step**: checks if the performance of the model meets the specified threshold\n",
    "1. **Register step**: registers a version of the model in the SageMaker model registry\n",
    "\n",
    "ðŸ’¡ You can use subclass compatibility for [workflow pipeline job steps](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#steps) to build job abstractions and use exactly the same code to configure the pipeline as the code for running processing, training, transform, and tuning jobs from the previous step notebooks. You also can use [PipelineSession](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.pipeline_context.PipelineSession) context instead of `sagemaker_session` to capture the run calls such as `processor.run()` or `estimator.fit()` but not run until the pipeline is created and executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe61a9b-ea0e-45b7-b37f-37684c2d7d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = PipelineSession()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f10b118-2985-41a9-b1af-da7111060f68",
   "metadata": {},
   "source": [
    "#### Processing step\n",
    "Re-use the processor definition and `sklearn_processor.run()` code from the step 2 to create a pipeline processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ecc9b-aeb3-4ade-a0c6-0274cb6064c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = \"y\"\n",
    "    \n",
    "    # Load data\n",
    "    df_data = pd.read_csv(os.path.join(args.filepath, args.filename), sep=\";\")\n",
    "\n",
    "    # Indicator variable to capture when pdays takes a value of 999\n",
    "    df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "    # Indicator for individuals not actively employed\n",
    "    df_data[\"not_working\"] = np.where(\n",
    "        np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    # remove unnecessary data\n",
    "    df_model_data = df_data.drop(\n",
    "        [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_model_data = pd.get_dummies(df_model_data)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "    # Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "    df_model_data = pd.concat(\n",
    "        [\n",
    "            df_model_data[\"y_yes\"].rename(target_col),\n",
    "            df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df_model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "    \n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "    \n",
    "    #Â Save the baseline dataset for model monitoring\n",
    "    df_model_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=False, header=False)\n",
    "    \n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664feff0-e1e6-4b4e-bcea-d31617725bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=\"0.23-1\",\n",
    "        role=sm_role,\n",
    "        instance_type=process_instance_type_param,\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{pipeline_name}/preprocess\",\n",
    "        sagemaker_session=session,\n",
    "    )\n",
    "    \n",
    "processing_inputs=[\n",
    "    ProcessingInput(source=input_s3_url_param, destination=\"/opt/ml/processing/input\")\n",
    "]\n",
    "\n",
    "processing_outputs=[\n",
    "    ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/output/train\", \n",
    "                     destination=train_s3_url),\n",
    "    ProcessingOutput(output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\",\n",
    "                     destination=validation_s3_url),\n",
    "    ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test\",\n",
    "                     destination=test_s3_url),\n",
    "    ProcessingOutput(output_name=\"baseline_data\", source=\"/opt/ml/processing/output/baseline\", \n",
    "                     destination=baseline_s3_url),\n",
    "]\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    ")\n",
    "    \n",
    "# Define processing step\n",
    "step_process = ProcessingStep(\n",
    "    name=f\"{pipeline_name}-preprocess-data\",\n",
    "    step_args=processor_args,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21faa341-c920-47fc-bf79-1453f7982f95",
   "metadata": {},
   "source": [
    "#### Training step\n",
    "Re-use the estimator definition and hyperparameters setup code from the step 2 to create a pipeline model training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ae5fa-af26-46a1-9287-e0d35780ffa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgboost_image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.5-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f8317-4758-420a-b8e9-1a3e23ed3493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sm_role, \n",
    "    instance_type=train_instance_type_param,\n",
    "    instance_count=train_instance_count_param,\n",
    "    output_path=output_s3_url,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=f\"{pipeline_name}/train\",\n",
    ")\n",
    "\n",
    "# Define algorithm hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150, # the number of rounds to run the training\n",
    "    max_depth=5, # maximum depth of a tree\n",
    "    eta=0.5, # step size shrinkage used in updates to prevent overfitting\n",
    "    alpha=2.5, # L1 regularization term on weights\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\", # evaluation metrics for validation data\n",
    "    subsample=0.8, # subsample ratio of the training instance\n",
    "    colsample_bytree=0.8, # subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=3, # minimum sum of instance weight (hessian) needed in a child\n",
    "    early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "    verbosity=1, # verbosity of printing messages\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"train_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"validation_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_args = estimator.fit(training_inputs)\n",
    "\n",
    "# Define training step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{pipeline_name}-train\",\n",
    "    step_args=training_args\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b97f365c-94c4-4403-8a8c-b79399b3d665",
   "metadata": {},
   "source": [
    "#### Evaluation step\n",
    "Create a model evaluation script to check if the model performance meets the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b40bf5-c2f1-4a09-9f85-a5d9728ad563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile evaluation.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    # All paths are local for the processing container\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    test_x_path = \"/opt/ml/processing/test/test_x.csv\"\n",
    "    test_y_path = \"/opt/ml/processing/test/test_y.csv\"\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    output_prediction_path = \"/opt/ml/processing/output/\"\n",
    "        \n",
    "    # Read model tar file\n",
    "    with tarfile.open(model_path, \"r:gz\") as t:\n",
    "        t.extractall(path=\".\")\n",
    "    \n",
    "    # Load model\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(\"xgboost-model\")\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = xgb.DMatrix(pd.read_csv(test_x_path, header=None).values)\n",
    "    y_test = pd.read_csv(test_y_path, header=None).to_numpy()\n",
    "\n",
    "    # Run predictions\n",
    "    probability = model.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probability)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc_score\": {\n",
    "                \"value\": auc_score,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Save evaluation report\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"{output_dir}/evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "    \n",
    "    # Save prediction baseline file - we need it later for the model quality monitoring\n",
    "    pd.DataFrame({\"prediction\":np.array(np.round(probability), dtype=int),\n",
    "                  \"probability\":probability,\n",
    "                  \"label\":y_test.squeeze()}\n",
    "                ).to_csv(os.path.join(output_prediction_path, 'prediction_baseline/prediction_baseline.csv'), index=False, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "220ce484-22bf-42e3-9a13-d5699467242a",
   "metadata": {},
   "source": [
    "Create a processor to run the evaluation script and construct the evaluation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb4df0-6457-4480-8a40-a646173e7c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_processor = ScriptProcessor(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sm_role,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=process_instance_type_param,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{pipeline_name}/evaluate\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "eval_inputs=[\n",
    "    ProcessingInput(source=step_train.properties.ModelArtifacts.S3ModelArtifacts, \n",
    "                    destination=\"/opt/ml/processing/model\"),\n",
    "    ProcessingInput(source=step_process.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri, \n",
    "                    destination=\"/opt/ml/processing/test\"),\n",
    "]\n",
    "\n",
    "eval_outputs=[\n",
    "    ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", \n",
    "                     destination=evaluation_s3_url),\n",
    "    ProcessingOutput(output_name=\"prediction_baseline_data\", source=\"/opt/ml/processing/output/prediction_baseline\", \n",
    "                     destination=prediction_baseline_s3_url),\n",
    "]\n",
    "\n",
    "eval_args = script_processor.run(\n",
    "    inputs=eval_inputs,\n",
    "    outputs=eval_outputs,\n",
    "    code=\"evaluation.py\",\n",
    ")\n",
    "    \n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ModelEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=f\"{pipeline_name}-evaluate-model\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5b0157d-f99b-4548-9de7-7188f62369c8",
   "metadata": {},
   "source": [
    "Use [property files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) to store information from the output of a processing step. This is particularly useful when analyzing the results of a processing step to decide how a conditional step should be executed. The `JsonGet` function processes a property file and enables you to use [`JsonPath`](https://github.com/json-path/JsonPath) notation to query the property JSON file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c93a5348-9c06-416a-a4b2-0c83e4ea34f4",
   "metadata": {},
   "source": [
    "#### Register step\n",
    "The register step creates a SageMaker model and registers a new version of a model in the SageMaker Model Registry within a [model package group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f94ac1-5b7b-41ea-bfef-d836efb8b6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=f\"from-idea-to-prod-xgboost-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status_param,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "step_register = ModelStep(\n",
    "    name=f\"{pipeline_name}-register\",\n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "494111e4-0649-49aa-984b-f9001324cddc",
   "metadata": {},
   "source": [
    "#### Fail step\n",
    "Add a Pipelines [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) to stop the pipeline execution if the model performance metric doesn't meet the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84156042-8711-4993-a12b-0020d199630e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=f\"{pipeline_name}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to AUC Score >\", test_score_threshold_param]),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51c6c5db-33f7-4ec7-b662-b574f65c3b83",
   "metadata": {},
   "source": [
    "#### Condition step\n",
    "The condition step checks the model performance score and conditionally creates a model and registers it in the model registry, or stops and fails the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d15f83-cec9-4451-92c1-1f75f6db49eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=test_score_threshold_param,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{pipeline_name}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79095789-64d7-47b5-952c-d70b8500ed0c",
   "metadata": {},
   "source": [
    "#### Construct the pipeline \n",
    "You don't need to manually define a sequence of the steps, as SageMaker automatically derives the processing flow based on data dependencies between pipeline's steps. You also don't need to manage transfer of artifacts and datasets from one pipeline's step to another, because SageMaker automatically takes care of the data flow.\n",
    "\n",
    "Pipelines are integrated with SageMaker Experiments. By default, when SageMaker Pipelines creates and executes a pipeline, the following SageMaker Experiments entities are created if they don't exist:\n",
    "\n",
    "- An experiment for the pipeline. Experiment name is the name of the pipeline\n",
    "- A run group for every execution of the pipeline\n",
    "- A run that's added to the run group for each SageMaker job created in a pipeline execution step\n",
    "\n",
    "Refer to the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-experiments.html) for more details on experiment integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e7177-84bf-4271-9036-7af3d640daba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        input_s3_url_param,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f3608ce-fcab-4e89-be8f-07a060675e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on the data dependencies between the pipeline's steps, SageMaker builds the following DAG with the data flow in your pipeline:\n",
    "![](img/pipeline-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b8030-aea8-45bb-a4b1-f20b09df7a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d05813-b615-463b-9b90-67f45c9444cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_definition = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "pipeline_definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f297037d-a04c-463a-9353-c362fcb3677d",
   "metadata": {},
   "source": [
    "Look at and understand the pipeline definition JSON. For example, you can see, how the pipeline paramemters are defined and how are they used.\n",
    "\n",
    "Definition:\n",
    "```json\n",
    "'Parameters': [{'Name': 'ProcessingInstanceType',\n",
    "   'Type': 'String',\n",
    "   'DefaultValue': 'ml.c5.xlarge'},\n",
    "               ...\n",
    "               ]\n",
    "```\n",
    "\n",
    "Parameter substitution:\n",
    "```json\n",
    "'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType':{'Get':'Parameters.ProcessingInstanceType'}\n",
    "```\n",
    "\n",
    "You can also see that the processing script `preprocessing.py` is automatically uploaded to an Amazon S3 bucket and the S3 url is specified as one of the step's `ProcessingInputs`:\n",
    "```json\n",
    "{'InputName': 'code',\n",
    "      'AppManaged': False,\n",
    "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-XXXX/PreprocessData-e5d4c2b08e616c264c9dc5053871519a/input/code/preprocessing.py',\n",
    "       'LocalPath': '/opt/ml/processing/input/code',\n",
    "       'S3DataType': 'S3Prefix',\n",
    "       'S3InputMode': 'File',\n",
    "       'S3DataDistributionType': 'FullyReplicated',\n",
    "       'S3CompressionType': 'None'}}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c42089e-1ccf-491c-85f1-4c685f5fae07",
   "metadata": {},
   "source": [
    "## Execute the pipeline\n",
    "The following code starts an execution of the pipeline with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30569d9c-08b7-4f86-ad86-02771ce47ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=process_instance_type,\n",
    "        TrainingInstanceType=train_instance_type,\n",
    "        TrainingInstanceCount=train_instance_count,\n",
    "        ModelApprovalStatus=\"PendingManualApproval\",\n",
    "        TestScoreThreshold=0.75,\n",
    "        InputDataUrl=input_s3_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57742436-a460-4ed8-a79d-131c63261b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment this call if you want the notebook to wait until the pipeline's execution finished\n",
    "# Execution time of this pipeline is about 13 minutes\n",
    "# execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573b6e4-d905-454e-9d14-6ea1af592279",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c70ee2a-a099-467a-b13c-85fc567f1e4f",
   "metadata": {},
   "source": [
    "You can follow the pipeline execution in Studio by selecting **Pipelines** in **SageMaker Home**:\n",
    "\n",
    "<img src=\"img/pipelines-widget.png\" width=\"400\"/>\n",
    "\n",
    "Double click on your pipeline name in the list of the pipelines to see the pipeline executions and other data:\n",
    "\n",
    "![](img/pipelines-list.png)\n",
    "\n",
    "After a successful execution you can open the pipeline execution graph and see details for each pipeline step:\n",
    "\n",
    "![](img/pipeline-execution-graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc25fb32-eaab-4b01-8ccc-a79908afce80",
   "metadata": {},
   "source": [
    "## Batch transform in the pipeline\n",
    "You can integrate a batch transform step using the trained model in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848224f-40be-4b84-ba11-78505227444b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.inputs import CreateModelInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ffaa4-0a71-426b-9379-732cce320bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, create a SageMaker model for the transform\n",
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=f\"from-idea-to-prod-xgboost-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "#Â Define create model step\n",
    "step_create_model = ModelStep(\n",
    "    name=f\"{pipeline_name}-model\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc7794-bc9e-4019-8d13-cf4d60db1b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the defined model to create a tranformer\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"s3://{bucket_name}/{bucket_prefix}/transform\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "    \n",
    "transform_args = transformer.transform(    \n",
    "    data=step_process.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\", \n",
    ")\n",
    "            \n",
    "# Create the transform step\n",
    "step_transform = TransformStep(\n",
    "    name=f\"{pipeline_name}-transform\", \n",
    "    step_args=transform_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb20bd3-18af-453b-add0-dcbe4b055dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add create model, register model, and transform steps to the \"true\" branch of the condition\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{pipeline_name}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model, step_register, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b15371-7f8d-4eb5-8a5a-25963433ff34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        input_s3_url_param,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f2ca7-bf91-421b-bc7e-2775fdf7053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a6dfdbc-af2f-4555-8750-6f4c36e0a981",
   "metadata": {},
   "source": [
    "The new pipeline contains now the steps for creating the model and executing batch transform:\n",
    "![](img/pipeline-graph-with-transform.png)\n",
    "\n",
    "Optionally you can start the new pipeline execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256e74b-5b20-4b7e-a3a4-55e30342707e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=process_instance_type,\n",
    "        TrainingInstanceType=train_instance_type,\n",
    "        TrainingInstanceCount=train_instance_count,\n",
    "        ModelApprovalStatus=\"PendingManualApproval\",\n",
    "        TestScoreThreshold=0.75,\n",
    "        InputDataUrl=input_s3_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110af47f-ec84-4647-bb5a-0a973d446dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c1eb4e6-6010-49c3-ada7-9935bf8644b8",
   "metadata": {},
   "source": [
    "## Continue with the workshop flow\n",
    "After finishing this lab, you can continue with the step 4 and 5 [notebooks](04-sagemaker-project.ipynb) or go directly to the step 6 [notebook](06-monitoring.ipynb).\n",
    "\n",
    "**Step 4 and 5**: Use SageMaker Projects to implement CI/CD automation pipelines for model build and deployment\n",
    "\n",
    "**Step 6**: Data and model quality monitoring."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaf9dea1-ec92-4a28-8523-31c990c274a4",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add [data quality check](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and [model explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-clarify-check) steps. Add model metrics calculated by [SageMaker Clarify](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html) to the model metadata in the model registry\n",
    "- Add event-driven launching of the ML pipeline as soon as a new dataset is uploaded to an Amazon S3 bucket. You can use [Amazon EventBridge integeration](https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html#pipeline-eventbridge-schedule) to implement various event-driven workflows\n",
    "- Use a designated IAM execution role for the pipeline execution\n",
    "- Add data encryption by using S3 bucket encryption and AWS KMS keys for container EBS volume encryption"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f8f9efc-0920-4077-bd58-9f5514550412",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Automate Machine Learning Workflows](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-mlops-automate-ml-workflows/)\n",
    "- [Amazon SageMaker Feature Store workshop](https://github.com/aws-samples/amazon-sagemaker-feature-store-end-to-end-workshop)\n",
    "- [Amazon SageMaker Model Building Pipeline](https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "874abcd0-2241-4118-9191-011215b861cd",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bfea5-a835-4adc-81f0-e5355bf53a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc7baf-75d2-43fc-9c23-aadb29b72047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
