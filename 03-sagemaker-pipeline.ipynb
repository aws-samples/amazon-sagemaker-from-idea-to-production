{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575c15ae-ffe0-4d93-84d8-bf96278c0372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Add an ML pipeline\n",
    "\n",
    "In this step you automate our end-to-end ML workflow using [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) and [Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html). You make feature engineering re-usable, repeatable, and scaleable using [Amazon SageMaker Feature Store](https://aws.amazon.com/sagemaker/feature-store/).\n",
    "\n",
    "![](img/six-steps-3.png)\n",
    "\n",
    "<div class=\"alert alert-info\"> Make sure you using <code>Data Science 3.0</code> image in Studio for this notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6ca42d3f-7231-44cc-83f4-a54c6a7995f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.212.0'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import pathlib\n",
    "import io\n",
    "import sagemaker\n",
    "from time import gmtime, strftime, sleep\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput, \n",
    "    ProcessingOutput, \n",
    "    ScriptProcessor\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    TrainingStep, \n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig, \n",
    "    ClarifyCheckStep, \n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThan,\n",
    "    ConditionGreaterThanOrEqualTo\n",
    ")\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import (\n",
    "    Join,\n",
    "    JsonGet\n",
    ")\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource, \n",
    "    ModelMetrics, \n",
    "    FileSource\n",
    ")\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig \n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.step_outputs import get_step\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "015980fe-d2c9-44d5-aa99-08e49bc50c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "313ac5a8-2730-45fd-8bed-1559c422748c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "baseline_s3_url                         -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "bucket_name                             -> 'sagemaker-us-east-1-906545278380'\n",
      "bucket_prefix                           -> 'from-idea-to-prod/xgboost'\n",
      "dataset_feature_group_name              -> 'from-idea-to-prod-03-11-15-15'\n",
      "dataset_file_local_path                 -> 'data/bank-additional/bank-additional-full.csv'\n",
      "domain_id                               -> 'd-9oteoq7mqbpp'\n",
      "evaluation_s3_url                       -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "experiment_name                         -> 'from-idea-to-prod-experiment-09-18-03-39'\n",
      "feature_store_bucket_prefix             -> 'from-idea-to-prod/feature-store'\n",
      "initialized                             -> True\n",
      "input_s3_url                            -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "model_package_group_name                -> 'from-idea-to-prod-model-group-03-14-21-18'\n",
      "output_s3_url                           -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "pipeline_name                           -> 'from-idea-to-prod-pipeline-03-14-21-18'\n",
      "prediction_baseline_s3_url              -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "region                                  -> 'us-east-1'\n",
      "sm_role                                 -> 'arn:aws:iam::906545278380:role/sm-domain-workshop\n",
      "target_col                              -> 'y'\n",
      "test_s3_url                             -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "train_s3_url                            -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "training_job_name                       -> 'from-idea-to-prod-training-2024-03-09-21-58-24-18\n",
      "validation_s3_url                       -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd6d8b-a230-4bf8-a575-2c6dcff55615",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "152b507e-f512-49c9-9f59-6477133bd118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set names of pipeline objects\n",
    "project = \"from-idea-to-prod\"\n",
    "\n",
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())\n",
    "pipeline_name = f\"{project}-pipeline-{current_timestamp}\"\n",
    "pipeline_model_name = f\"{project}-model-xgb\"\n",
    "model_package_group_name = f\"{project}-model-group-{current_timestamp}\"\n",
    "endpoint_config_name = f\"{project}-endpoint-config\"\n",
    "endpoint_name = f\"{project}-endpoint\"\n",
    "model_approval_status = \"PendingManualApproval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c947da3b-e046-4dea-9897-1717c5bbc3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set instance types and counts\n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "process_instance_count = 1\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0e9be066-8452-4058-b50e-e3027cb466b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set S3 urls for processed data\n",
    "output_s3_prefix = f\"s3://{bucket_name}/{bucket_prefix}\"\n",
    "train_s3_url = f\"{output_s3_prefix}/train\"\n",
    "validation_s3_url = f\"{output_s3_prefix}/validation\"\n",
    "test_s3_url = f\"{output_s3_prefix}/test\"\n",
    "baseline_s3_url = f\"{output_s3_prefix}/baseline\"\n",
    "\n",
    "evaluation_s3_url = f\"{output_s3_prefix}/evaluation\"\n",
    "prediction_baseline_s3_url = f\"{output_s3_prefix}/prediction_baseline\"\n",
    "\n",
    "output_s3_url = f\"{output_s3_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f3d649cf-b64c-4978-b3f5-cf767b7f1870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_s3_url' (str)\n",
      "Stored 'validation_s3_url' (str)\n",
      "Stored 'test_s3_url' (str)\n",
      "Stored 'baseline_s3_url' (str)\n",
      "Stored 'pipeline_name' (str)\n",
      "Stored 'model_package_group_name' (str)\n",
      "Stored 'evaluation_s3_url' (str)\n",
      "Stored 'prediction_baseline_s3_url' (str)\n",
      "Stored 'output_s3_url' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_s3_url\n",
    "%store validation_s3_url\n",
    "%store test_s3_url\n",
    "%store baseline_s3_url\n",
    "%store pipeline_name\n",
    "%store model_package_group_name\n",
    "%store evaluation_s3_url\n",
    "%store prediction_baseline_s3_url\n",
    "%store output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "54b75414-0239-4682-a435-22d646bb16cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/train\n",
      "Validation S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/validation\n",
      "Test S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test\n",
      "Data baseline S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/baseline\n",
      "Evaluation metrics S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/evaluation\n",
      "Model prediction baseline S3 url: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/prediction_baseline\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train S3 url: {train_s3_url}\")\n",
    "print(f\"Validation S3 url: {validation_s3_url}\")\n",
    "print(f\"Test S3 url: {test_s3_url}\")\n",
    "print(f\"Data baseline S3 url: {baseline_s3_url}\")\n",
    "print(f\"Evaluation metrics S3 url: {evaluation_s3_url}\")\n",
    "print(f\"Model prediction baseline S3 url: {prediction_baseline_s3_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ea883-3bd9-4947-a0c8-7c3a80c1bbca",
   "metadata": {},
   "source": [
    "## Create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00ef9a-a6fe-4415-9847-bcfa97f32c44",
   "metadata": {},
   "source": [
    "### Setup pipeline parameters\n",
    "SageMaker Pipelines supports [parameterization](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html), which allows you to specify input parameters at runtime without changing your pipeline code. You can use the parameter classes available under the [`sagemaker.workflow.parameters`](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#parameters) module.\n",
    "Parameters have a default value, which you can override by specifying parameter values when starting a pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "05f370b6-1ee3-4bc6-ae85-5eef37878196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set model approval status for the model registry\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=model_approval_status\n",
    ")\n",
    "\n",
    "#Â Minimal threshold for model performance on the test dataset\n",
    "test_score_threshold_param = ParameterFloat(\n",
    "    name=\"TestScoreThreshold\", \n",
    "    default_value=0.75\n",
    ")\n",
    "\n",
    "# Parametrize the S3 url for input dataset\n",
    "input_s3_url_param = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=input_s3_url,\n",
    ")\n",
    "\n",
    "# Model package group name\n",
    "model_package_group_name_param = ParameterString(\n",
    "    name=\"ModelPackageGroupName\",\n",
    "    default_value=model_package_group_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "0bf3312a-c88e-4e52-83bd-c48ab1d45667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skprocessor_framework_version = \"0.23-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c3182-d926-4aa5-b8c0-23d7c782f116",
   "metadata": {},
   "source": [
    "### Build the pipeline steps\n",
    "You create a pipeline with the following:\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| **Data processing** | runs a SageMaker processing job for feature engineering and dataset split|\n",
    "| **Training** | runs a SageMaker training job using XGBoost algorithm |\n",
    "| **Evaluation** | evaluates the performance of the trained model |\n",
    "| **Condition** | checks if the performance of the model meets the specified threshold |\n",
    "| **Register model** | registers a version of the model in the SageMaker model registry |\n",
    "\n",
    "ðŸ’¡ You can use subclass compatibility for [workflow pipeline job steps](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#steps) to build job abstractions and use exactly the same code to configure the pipeline as the code for running processing, training, transform, and tuning jobs from the previous step notebooks. You also can use [PipelineSession](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.pipeline_context.PipelineSession) context instead of `sagemaker_session` to capture the run calls such as `processor.run()` or `estimator.fit()` but not run until the pipeline is created and executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "dbe61a9b-ea0e-45b7-b37f-37684c2d7d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note the usage of PipelineSession instead of Session\n",
    "session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10b118-2985-41a9-b1af-da7111060f68",
   "metadata": {},
   "source": [
    "#### Processing step\n",
    "Re-use the processor definition and `sklearn_processor.run()` code from the step 2 [notebook](./02-sagemaker-containers.ipynb) to create a pipeline processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "f06ecc9b-aeb3-4ade-a0c6-0274cb6064c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "def process_data(df_data):\n",
    "    target_col = \"y\"\n",
    "        \n",
    "    # Indicator variable to capture when pdays takes a value of 999\n",
    "    df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "    # Indicator for individuals not actively employed\n",
    "    df_data[\"not_working\"] = np.where(\n",
    "        np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    # remove unnecessary data\n",
    "    df_model_data = df_data.drop(\n",
    "        [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "    bins = [18, 30, 40, 50, 60, 70, 90]\n",
    "    labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70-plus']\n",
    "\n",
    "    df_model_data['age_range'] = pd.cut(df_model_data.age, bins, labels=labels, include_lowest=True)\n",
    "    df_model_data = pd.concat([df_model_data, pd.get_dummies(df_model_data['age_range'], prefix='age', dtype=int)], axis=1)\n",
    "    df_model_data.drop('age', axis=1, inplace=True)\n",
    "    df_model_data.drop('age_range', axis=1, inplace=True)\n",
    "\n",
    "    scaled_features = ['pdays', 'previous', 'campaign']\n",
    "    df_model_data[scaled_features] = MinMaxScaler().fit_transform(df_model_data[scaled_features])\n",
    "\n",
    "    df_model_data = pd.get_dummies(df_model_data, dtype=int)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "    # Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "    df_model_data = pd.concat(\n",
    "        [\n",
    "            df_model_data[\"y_yes\"].rename(target_col),\n",
    "            df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    return df_model_data\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = \"y\"\n",
    "    \n",
    "    # process data\n",
    "    df_model_data = process_data(pd.read_csv(os.path.join(args.filepath, args.filename), sep=\";\"))\n",
    "\n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df_model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "    \n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "    \n",
    "    #Â Save the baseline dataset for model monitoring\n",
    "    df_model_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=False, header=False)\n",
    "    \n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "664feff0-e1e6-4b4e-bcea-d31617725bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=skprocessor_framework_version,\n",
    "        role=sm_role,\n",
    "        instance_type=process_instance_type_param,\n",
    "        instance_count=process_instance_count,\n",
    "        base_job_name=f\"{project}-preprocess\",\n",
    "        sagemaker_session=session,\n",
    "    )\n",
    "    \n",
    "processing_inputs=[\n",
    "    ProcessingInput(\n",
    "        source=input_s3_url_param, \n",
    "        destination=\"/opt/ml/processing/input\"\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs=[\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train_data\",\n",
    "        source=\"/opt/ml/processing/output/train\", \n",
    "        destination=train_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation_data\",\n",
    "        source=\"/opt/ml/processing/output/validation\",\n",
    "        destination=validation_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test_data\", \n",
    "        source=\"/opt/ml/processing/output/test\",\n",
    "        destination=test_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"baseline_data\",\n",
    "        source=\"/opt/ml/processing/output/baseline\", \n",
    "        destination=baseline_s3_url\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "f82fca0c-fa72-4e43-b4a3-ba07d14c1389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor_args = sklearn_processor.run(\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    ")\n",
    "    \n",
    "# Define processing step\n",
    "step_process = ProcessingStep(\n",
    "    name=f\"{project}-preprocess\",\n",
    "    step_args=processor_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21faa341-c920-47fc-bf79-1453f7982f95",
   "metadata": {},
   "source": [
    "#### Training step\n",
    "Re-use the estimator definition and hyperparameters setup code from the step 2 [notebook](./02-sagemaker-containers.ipynb) to create a model training pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "3f1ae5fa-af26-46a1-9287-e0d35780ffa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "xgboost_image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.5-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b06f8317-4758-420a-b8e9-1a3e23ed3493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sm_role, \n",
    "    instance_type=train_instance_type_param,\n",
    "    instance_count=train_instance_count_param,\n",
    "    output_path=output_s3_url,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=f\"{project}-train\",\n",
    ")\n",
    "\n",
    "# Define algorithm hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=100, # the number of rounds to run the training\n",
    "    max_depth=3, # maximum depth of a tree\n",
    "    eta=0.5, # step size shrinkage used in updates to prevent overfitting\n",
    "    alpha=2.5, # L1 regularization term on weights\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\", # evaluation metrics for validation data\n",
    "    subsample=0.8, # subsample ratio of the training instance\n",
    "    colsample_bytree=0.8, # subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=3, # minimum sum of instance weight (hessian) needed in a child\n",
    "    early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "    verbosity=1, # verbosity of printing messages\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"train_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"validation_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_args = estimator.fit(training_inputs)\n",
    "\n",
    "# Define training step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{project}-train\",\n",
    "    step_args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f365c-94c4-4403-8a8c-b79399b3d665",
   "metadata": {},
   "source": [
    "#### Evaluation step\n",
    "Create a model evaluation script to check if the model performance meets the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d8b40bf5-c2f1-4a09-9f85-a5d9728ad563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluation.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    # All paths are local for the processing container\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    test_x_path = \"/opt/ml/processing/test/test_x.csv\"\n",
    "    test_y_path = \"/opt/ml/processing/test/test_y.csv\"\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    output_prediction_path = \"/opt/ml/processing/output/\"\n",
    "        \n",
    "    # Read model tar file\n",
    "    with tarfile.open(model_path, \"r:gz\") as t:\n",
    "        t.extractall(path=\".\")\n",
    "    \n",
    "    # Load model\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(\"xgboost-model\")\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = xgb.DMatrix(pd.read_csv(test_x_path, header=None).values)\n",
    "    y_test = pd.read_csv(test_y_path, header=None).to_numpy()\n",
    "\n",
    "    # Run predictions\n",
    "    probability = model.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probability)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc_score\": {\n",
    "                \"value\": auc_score,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Save evaluation report\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"{output_dir}/evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "    \n",
    "    # Save prediction baseline file - you need it later for the model quality monitoring\n",
    "    pd.DataFrame({\"prediction\":np.array(np.round(probability), dtype=int),\n",
    "                  \"probability\":probability,\n",
    "                  \"label\":y_test.squeeze()}\n",
    "                ).to_csv(os.path.join(output_prediction_path, 'prediction_baseline/prediction_baseline.csv'), index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ce484-22bf-42e3-9a13-d5699467242a",
   "metadata": {},
   "source": [
    "Create a processor to run the evaluation script and construct the evaluation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "f8bb4df0-6457-4480-8a40-a646173e7c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_processor = ScriptProcessor(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sm_role,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=process_instance_type_param,\n",
    "    instance_count=process_instance_count,\n",
    "    base_job_name=f\"{project}-evaluate\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "eval_inputs=[\n",
    "    ProcessingInput(source=step_train.properties.ModelArtifacts.S3ModelArtifacts, \n",
    "                    destination=\"/opt/ml/processing/model\"),\n",
    "    ProcessingInput(source=step_process.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri, \n",
    "                    destination=\"/opt/ml/processing/test\"),\n",
    "]\n",
    "\n",
    "eval_outputs=[\n",
    "    ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", \n",
    "                     destination=evaluation_s3_url),\n",
    "    ProcessingOutput(output_name=\"prediction_baseline_data\", source=\"/opt/ml/processing/output/prediction_baseline\", \n",
    "                     destination=prediction_baseline_s3_url),\n",
    "]\n",
    "\n",
    "eval_args = script_processor.run(\n",
    "    inputs=eval_inputs,\n",
    "    outputs=eval_outputs,\n",
    "    code=\"evaluation.py\",\n",
    ")\n",
    "    \n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ModelEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=f\"{project}-evaluate\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0157d-f99b-4548-9de7-7188f62369c8",
   "metadata": {},
   "source": [
    "Use [property files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) to store information from the output of a processing step. This is particularly useful when analyzing the results of a processing step to decide how a conditional step should be executed. The `JsonGet` function processes a property file and enables you to use [`JsonPath`](https://github.com/json-path/JsonPath) notation to query the property JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a5348-9c06-416a-a4b2-0c83e4ea34f4",
   "metadata": {},
   "source": [
    "#### Register step\n",
    "The register step creates a SageMaker model and registers a new version of a model in the SageMaker Model Registry within a [model package group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "22f94ac1-5b7b-41ea-bfef-d836efb8b6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=f\"from-idea-to-prod-xgboost-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name_param,\n",
    "    approval_status=model_approval_status_param,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "step_register = ModelStep(\n",
    "    name=f\"{project}-register\",\n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494111e4-0649-49aa-984b-f9001324cddc",
   "metadata": {},
   "source": [
    "#### Fail step\n",
    "Add a Pipelines [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) to stop the pipeline execution if the model performance metric doesn't meet the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "84156042-8711-4993-a12b-0020d199630e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=f\"{project}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to AUC Score >\", test_score_threshold_param]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c6c5db-33f7-4ec7-b662-b574f65c3b83",
   "metadata": {},
   "source": [
    "#### Condition step\n",
    "The last step to add is a condition step. The condition step checks the model performance score calculated in the evaluation step and conditionally creates a model and registers it in the model registry, or stops and fails the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "64d15f83-cec9-4451-92c1-1f75f6db49eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=test_score_threshold_param,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{project}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79095789-64d7-47b5-952c-d70b8500ed0c",
   "metadata": {},
   "source": [
    "### Construct a pipeline \n",
    "Having all steps, you can now constract an end-to-end pipeline.\n",
    "You don't need to manually define a sequence of the steps, as SageMaker automatically derives the processing flow based on data dependencies between pipeline's steps. You also don't need to manage transfer of artifacts and datasets from one pipeline's step to another, because SageMaker automatically takes care of the data flow.\n",
    "\n",
    "Pipelines are integrated with SageMaker Experiments. By default, when SageMaker Pipelines creates and executes a pipeline, the following SageMaker Experiments entities are created if they don't exist:\n",
    "\n",
    "- An experiment for the pipeline. Experiment name is the name of the pipeline\n",
    "- A run group for every execution of the pipeline\n",
    "- A run that's added to the run group for each SageMaker job created in a pipeline execution step\n",
    "\n",
    "Refer to the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-experiments.html) for more details on experiment integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "114e7177-84bf-4271-9036-7af3d640daba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_def_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        input_s3_url_param,\n",
    "        model_package_group_name_param,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=session,\n",
    "    pipeline_definition_config=pipeline_def_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3608ce-fcab-4e89-be8f-07a060675e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on the data dependencies between the pipeline's steps, SageMaker builds the following DAG with the data flow in your pipeline:\n",
    "![](img/pipeline-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "b44b8030-aea8-45bb-a4b1-f20b09df7a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-14-21-18',\n",
       " 'ResponseMetadata': {'RequestId': '486149e3-a15f-440b-8ac5-9b49e265a119',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '486149e3-a15f-440b-8ac5-9b49e265a119',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '106',\n",
       "   'date': 'Sat, 16 Mar 2024 19:27:01 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d05813-b615-463b-9b90-67f45c9444cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_definition = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "pipeline_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297037d-a04c-463a-9353-c362fcb3677d",
   "metadata": {},
   "source": [
    "Look at and understand the pipeline definition JSON. For example, you can see, how the pipeline paramemters are defined and how are they used.\n",
    "\n",
    "Definition:\n",
    "```json\n",
    "'Parameters': [{'Name': 'ProcessingInstanceType',\n",
    "   'Type': 'String',\n",
    "   'DefaultValue': 'ml.c5.xlarge'},\n",
    "               ...\n",
    "               ]\n",
    "```\n",
    "\n",
    "Parameter substitution:\n",
    "```json\n",
    "'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType':{'Get':'Parameters.ProcessingInstanceType'}\n",
    "```\n",
    "\n",
    "You can also see that the processing script `preprocessing.py` is automatically uploaded to an Amazon S3 bucket and the S3 url is specified as one of the step's `ProcessingInputs`:\n",
    "```json\n",
    "{'InputName': 'code',\n",
    "      'AppManaged': False,\n",
    "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-XXXX/PreprocessData-e5d4c2b08e616c264c9dc5053871519a/input/code/preprocessing.py',\n",
    "       'LocalPath': '/opt/ml/processing/input/code',\n",
    "       'S3DataType': 'S3Prefix',\n",
    "       'S3InputMode': 'File',\n",
    "       'S3DataDistributionType': 'FullyReplicated',\n",
    "       'S3CompressionType': 'None'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42089e-1ccf-491c-85f1-4c685f5fae07",
   "metadata": {},
   "source": [
    "## Execute the pipeline\n",
    "The following code starts an execution of the pipeline with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "30569d9c-08b7-4f86-ad86-02771ce47ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=process_instance_type,\n",
    "        TrainingInstanceType=train_instance_type,\n",
    "        TrainingInstanceCount=train_instance_count,\n",
    "        ModelApprovalStatus=\"PendingManualApproval\",\n",
    "        TestScoreThreshold=0.75,\n",
    "        InputDataUrl=input_s3_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573b6e4-d905-454e-9d14-6ea1af592279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sleep(5)\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57742436-a460-4ed8-a79d-131c63261b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Un-comment this call if you want the notebook to wait until the pipeline's execution finished\n",
    "# Execution time of this pipeline is about 13 minutes\n",
    "# execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70ee2a-a099-467a-b13c-85fc567f1e4f",
   "metadata": {},
   "source": [
    "You can follow the pipeline execution in Studio by selecting **Pipelines** in **SageMaker Home**:\n",
    "\n",
    "<img src=\"img/pipelines-widget.png\" width=\"400\"/>\n",
    "\n",
    "Double click on your pipeline name in the list of the pipelines to see the pipeline executions and other data:\n",
    "\n",
    "![](img/pipelines-list.png)\n",
    "\n",
    "After a successful execution you can open the pipeline execution graph and see details for each pipeline step:\n",
    "\n",
    "![](img/pipeline-execution-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25fb32-eaab-4b01-8ccc-a79908afce80",
   "metadata": {},
   "source": [
    "## Batch transform in the pipeline\n",
    "You can integrate a batch transform step using the trained model in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848224f-40be-4b84-ba11-78505227444b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.inputs import CreateModelInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ffaa4-0a71-426b-9379-732cce320bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, create a SageMaker model for the transform\n",
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=f\"from-idea-to-prod-xgboost-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "model_create_args = model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\")\n",
    "\n",
    "#Â Define create model step\n",
    "step_create_model = ModelStep(\n",
    "    name=f\"{project}-model\",\n",
    "    step_args=model_create_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc7794-bc9e-4019-8d13-cf4d60db1b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the defined model to create a transformer\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"{output_s3_prefix}/transform\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "    \n",
    "transform_args = transformer.transform(    \n",
    "    data=step_process.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\", \n",
    ")\n",
    "            \n",
    "# Create the transform step\n",
    "step_transform = TransformStep(\n",
    "    name=f\"{project}-transform\", \n",
    "    step_args=transform_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb20bd3-18af-453b-add0-dcbe4b055dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add create model, register model, and transform steps to the \"true\" branch of the condition\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{project}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model, step_register, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b15371-7f8d-4eb5-8a5a-25963433ff34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_def_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        input_s3_url_param,\n",
    "        model_package_group_name_param,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=session,\n",
    "    pipeline_definition_config=pipeline_def_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f2ca7-bf91-421b-bc7e-2775fdf7053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6dfdbc-af2f-4555-8750-6f4c36e0a981",
   "metadata": {},
   "source": [
    "The new pipeline contains now the steps for creating the model and executing batch transform:\n",
    "![](img/pipeline-graph-with-transform.png)\n",
    "\n",
    "Optionally you can start the new pipeline execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256e74b-5b20-4b7e-a3a4-55e30342707e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution_batch_transform = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=process_instance_type,\n",
    "        TrainingInstanceType=train_instance_type,\n",
    "        TrainingInstanceCount=train_instance_count,\n",
    "        ModelApprovalStatus=\"PendingManualApproval\",\n",
    "        TestScoreThreshold=0.75,\n",
    "        InputDataUrl=input_s3_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d010bf6-36b9-424f-ad90-f43edea0d5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sleep(5)\n",
    "execution_batch_transform.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110af47f-ec84-4647-bb5a-0a973d446dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment this call if you want the notebook to wait until the pipeline's execution finished\n",
    "# Execution time of this pipeline is about 17 minutes\n",
    "# execution_batch_transform.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c2ceaf-152a-4754-8ab3-af3db1f741f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optional: Lift-and-shift your Python code to a pipeline with @step decorator\n",
    "One of the useful features of SageMaker is easy conversion of your existing Python code to SageMaker pipelines. You can develop Python functions to implement an ML workflow using SageMaker Python SDK and test all code locally in the notebook. When you want to create a pipeline, you can use a [`@step`](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#step-decorator) decorator to convert Python functions into pipeline steps. Refer to the SageMaker [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-step-decorator-create-pipeline.html) for more details and examples.\n",
    "\n",
    "The following session uses Python functions to implement workflow steps and then `@step` decorator to re-use the function as a pipeline step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7719d07f-0ca9-486d-a9f1-0f1d4663cd86",
   "metadata": {},
   "source": [
    "### Configuring defaults for AWS infrastructure\n",
    "You can use YAML configuration file to define the default values that are automatically passed to SageMaker APIs. It's especially convenient when you need to provide static parameters for infrastructure settings, such as VPC ids, Security Groups, KMS keys etc, or work with remote functions.\n",
    "\n",
    "Refer to [Configuring and using defaults with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk) documentation for examples and more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "fd10fbf3-55e1-4268-9d61-d936f4174d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/etc/xdg/sagemaker/config.yaml\n",
      "/root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Print default location of configuration files\n",
    "import os\n",
    "from platformdirs import site_config_dir, user_config_dir\n",
    "\n",
    "#Prints the location of the admin config file\n",
    "print(os.path.join(site_config_dir(\"sagemaker\"), \"config.yaml\"))\n",
    "\n",
    "#Prints the location of the user config file\n",
    "print(os.path.join(user_config_dir(\"sagemaker\"), \"config.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080919d0-78b8-40e8-9e18-da429c1128a7",
   "metadata": {},
   "source": [
    "The next cell creates a configuration file and sets default values for remote functions. These values are automatically passed to `@step` decorator and you don't need to specify them explicitely. Refer to [Configure your pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-step-decorator-cfg-pipeline.html) in the Developer Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b33320fa-f008-48d0-adbe-82af13a54708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "    PythonSDK:\n",
    "        Modules:\n",
    "            RemoteFunction:\n",
    "                InstanceType: ml.m5.xlarge\n",
    "                Dependencies: ./requirements.txt\n",
    "                IncludeLocalWorkDir: true\n",
    "                CustomFileFilter:\n",
    "                    IgnoreNamePatterns: # files or directories to ignore\n",
    "                        - \"*.ipynb\" # all notebook files\n",
    "                        - \"*.md\" # all markdown files\n",
    "                        - \"__pycache__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "41475d62-58e2-4f74-8bbc-2d9a6ece2ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy the configuration file to user config file location\n",
    "%mkdir -p {user_config_dir(\"sagemaker\")}\n",
    "%cp config.yaml {os.path.join(user_config_dir(\"sagemaker\"), \"config.yaml\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73346693-b68e-4c9c-935e-1479c499ca33",
   "metadata": {},
   "source": [
    "### Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8a63a-2c4f-4cbd-9de6-4550b5710817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install xgboost for the local testing of the code\n",
    "%pip install -q xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4921f4-888d-4129-9921-23925d2fb5ec",
   "metadata": {},
   "source": [
    "Create a `requirement.txt` file for the pipeline environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "4b416e96-b3be-43f0-a434-42c05fb1e63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "sagemaker\n",
    "xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf153ef-1d32-41a2-8ffc-2da52b0047fb",
   "metadata": {},
   "source": [
    "###Â Develop and test local code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "6fb5d8d7-5456-4fc2-b667-b0fcf27258a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python function code is in the local files\n",
    "from pipeline_steps.preprocess import preprocess\n",
    "from pipeline_steps.evaluation import evaluate\n",
    "from pipeline_steps.register import register\n",
    "# from pipeline_steps.train import train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "1cc57963-63e6-4b9b-a94c-9607e748cbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize pipeline_steps/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "d9d7528d-0f1a-4d5b-bfdf-02821c55e6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize  pipeline_steps/evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "dd32d501-fe4b-46aa-aa25-24017bb6cf25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize  pipeline_steps/register.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "9c67dc19-d3dc-4f85-b5e1-2fd32df3e190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-09 21:14:11    5834924 bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "# check that there is dataset under S3 url\n",
    "!aws s3 ls {input_s3_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ebd12db9-d39f-4ceb-b3ec-0202f2aebd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split > train:(28831, 65) | validation:(8238, 65) | test:(4119, 65)\n",
      "## Pre-processing complete. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_data': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/train/train.csv',\n",
       " 'validation_data': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/validation/validation.csv',\n",
       " 'test_x_data': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test/test_x.csv',\n",
       " 'test_y_data': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test/test_y.csv',\n",
       " 'baseline_data': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/baseline/baseline.csv'}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can run your Python code locally and verify the corectness before constructing a pipeline\n",
    "r_preprocess = preprocess(\n",
    "    input_s3_url,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    ")\n",
    "r_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "7fac2704-ed92-4b5a-b7da-7260294c0cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:57:28     600465 test_x.csv\n",
      "2024-03-16 20:57:29       8238 test_y.csv\n"
     ]
    }
   ],
   "source": [
    "# check that the function generated output\n",
    "!aws s3 ls {output_s3_prefix}/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "10753f21-d082-4f4d-9b22-4efae201298d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a model tar file S3 url from a previous pipeline execution\n",
    "# you need to wait until the pipeline you created in the previous section completes the training step\n",
    "execution.wait()\n",
    "training_job_name = [s['Metadata'] for s in execution.list_steps() if s['StepName'] == f'{project}-train'][0]['TrainingJob']['Arn'].split('/')[1]\n",
    "model_s3_path = boto3.client('sagemaker').describe_training_job(TrainingJobName=training_job_name)['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "17f3140b-7efe-4df6-8caf-f57ac1210a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 19:33:17      11336 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# check that the model file is there\n",
    "!aws s3 ls {model_s3_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5d8f3495-cb98-4a09-95f1-f5e4fd555b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_metrics': {'auc_score': {'value': 0.7726359592480987}}}"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the evaluation code locally\n",
    "r_eval = evaluate(\n",
    "    test_x_data_s3_path=r_preprocess['test_x_data'],\n",
    "    test_y_data_s3_path=r_preprocess['test_y_data'],\n",
    "    model_s3_path=model_s3_path,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    ")\n",
    "r_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "7b64f35b-5b97-4a87-9f22-2769f8751a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE reports/\n",
      "                           PRE results/\n",
      "2024-03-16 20:57:34      63018 prediction_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# check that the evaluation function generated output\n",
    "!aws s3 ls {output_s3_prefix}/prediction_baseline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "bb3cba7f-b40a-4dbb-958a-e2f0c4536fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-16 19:33:24 Starting - Preparing the instances for training\n",
      "2024-03-16 19:33:24 Downloading - Downloading the training image\n",
      "2024-03-16 19:33:24 Training - Training image download completed. Training in progress.\n",
      "2024-03-16 19:33:24 Uploading - Uploading generated training model\n",
      "2024-03-16 19:33:24 Completed - Training job completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:906545278380:model-package/from-idea-to-prod-model-group-03-14-21-18/3'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model register code locally\n",
    "model_package_arn = register(\n",
    "    training_job_name=training_job_name,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_approval_status=model_approval_status,\n",
    "    evaluation_result=r_eval,\n",
    "    output_s3_prefix=output_s3_url,\n",
    ")\n",
    "model_package_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d4730a22-527b-4e8e-9516-32cc9caddf06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'from-idea-to-prod-model-group-03-14-21-18',\n",
       " 'ModelPackageVersion': 3,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:906545278380:model-package/from-idea-to-prod-model-group-03-14-21-18/3',\n",
       " 'CreationTime': datetime.datetime(2024, 3, 16, 20, 57, 43, 515000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1',\n",
       "    'ImageDigest': 'sha256:4cb2fa59a895f589854fd57de22cc0d0c749aec1a0afee48403d9d6252cb4ce4',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/output/from-idea-to-prod-train-kxqmemfg8c6w-nPDapDh3v1/output/model.tar.gz',\n",
       "    'Environment': {}}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.xlarge', 'ml.m5.large'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.xlarge', 'ml.m5.large'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'PendingManualApproval',\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:906545278380:user-profile/d-9oteoq7mqbpp/studio-user-54491630',\n",
       "  'UserProfileName': 'studio-user-54491630',\n",
       "  'DomainId': 'd-9oteoq7mqbpp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::906545278380:assumed-role/sm-domain-workshop-SageMakerExecutionRole-2tKGP8Kthe7Q/SageMaker',\n",
       "   'PrincipalId': 'AROA5GESPFWWPBQG4SGTG:SageMaker'}},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/output/from-idea-to-prod-train-kxqmemfg8c6w-nPDapDh3v1/output/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'SkipModelValidation': 'None',\n",
       " 'ResponseMetadata': {'RequestId': '12570e7f-853a-4bdd-8fd8-480f007a57f0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '12570e7f-853a-4bdd-8fd8-480f007a57f0',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1692',\n",
       "   'date': 'Sat, 16 Mar 2024 20:57:43 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that a new model version has been registered in the model package group\n",
    "boto3.client('sagemaker').describe_model_package(ModelPackageName=model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8ee79-c5e3-42e2-948f-bdbdc929d5c0",
   "metadata": {},
   "source": [
    "### Build a pipeline using @step decorator\n",
    "After local testing you can use the same Python code without any changes to construct a pipeline.\n",
    "\n",
    "The next cell creates pipeline steps. Note, that you use @step-decorated functions (preprocess, evaluate, register) and traditional pipeline steps (train) in the same pipeline and pass data between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d4ce8929-dfd1-459d-b9bf-87356a90288c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# preprocess data step\n",
    "processed_data_s3_path = step(preprocess, \n",
    "                              instance_type=process_instance_type_param,\n",
    "                              name=f\"{project}-preprocess\")(\n",
    "    data_s3_path=input_s3_url_param,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    ")\n",
    "\n",
    "# train step\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        processed_data_s3_path['train_data'],\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        processed_data_s3_path['validation_data'],\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{project}-train\",\n",
    "    step_args=estimator.fit(training_inputs)\n",
    ")    \n",
    "\n",
    "# evaluate step\n",
    "eval_result = step(evaluate,\n",
    "                   instance_type=process_instance_type_param,\n",
    "                   name=f\"{project}-evaluate\")(\n",
    "    test_x_data_s3_path=processed_data_s3_path['test_x_data'],\n",
    "    test_y_data_s3_path=processed_data_s3_path['test_y_data'],\n",
    "    model_s3_path=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    output_s3_prefix=output_s3_prefix\n",
    ")\n",
    "\n",
    "# register step\n",
    "model_package_arn = step(register,\n",
    "                         name=f\"{project}-register\")(\n",
    "    training_job_name=step_train.properties.TrainingJobName,\n",
    "    model_package_group_name=model_package_group_name_param,\n",
    "    model_approval_status=model_approval_status_param,\n",
    "    evaluation_result=eval_result,\n",
    "    output_s3_prefix=output_s3_url,\n",
    ")\n",
    "\n",
    "# fail step\n",
    "step_fail = FailStep(\n",
    "    name=f\"{project}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to AUC Score >\", test_score_threshold_param]),\n",
    ")\n",
    "\n",
    "# conditionally register step\n",
    "conditionally_register = ConditionStep(\n",
    "    name=f\"{project}-check-metrics\",\n",
    "    conditions=[\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=eval_result['classification_metrics']['auc_score']['value'],  \n",
    "            right=test_score_threshold_param,\n",
    "        )\n",
    "    ],\n",
    "    if_steps=[model_package_arn],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfb2a2-9bc0-42ba-9676-c21dee7a854f",
   "metadata": {},
   "source": [
    "To access a step output or pass data between steps you use [`DelayedReturn`](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.function_step.DelayedReturn) Python SDK class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4252f74-aeea-488b-8628-9dacd566384b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create and run a pipeline\n",
    "Now create and run the pipeline. You need to pass only the last step to `Pipeline` constructor. The SDK automatically builds a pipeline DAG based on data dependencies between steps. Refer to the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-step-decorator-create-pipeline.html#pipelines-step-define-delayed) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "01bdc186-436e-4b49-b322-a3d04b975ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_pipeline_step = conditionally_register\n",
    "\n",
    "pipeline_decorator = Pipeline(\n",
    "    name=f\"{pipeline_name}-decorator\",\n",
    "    parameters=[\n",
    "        input_s3_url_param,\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        model_package_group_name_param,\n",
    "    ],\n",
    "    steps=[last_pipeline_step]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "094ec445-a0da-4661-9bbd-eea8e1be45f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:58:22,360 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-register/2024-03-16-20-58-20-246/function\n",
      "2024-03-16 20:58:22,428 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-register/2024-03-16-20-58-20-246/arguments\n",
      "2024-03-16 20:58:22,595 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpj1noo4iq/requirements.txt'\n",
      "2024-03-16 20:58:22,637 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-register/2024-03-16-20-58-20-246/pre_exec_script_and_dependencies'\n",
      "2024-03-16 20:58:23,090 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmpy6qjfsi_/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-03-16 20:58:26,552 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpy6qjfsi_/workspace.zip'\n",
      "2024-03-16 20:58:27,124 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/sm_rf_user_ws/2024-03-16-20-58-20-246/workspace.zip'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:58:29,098 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-evaluate/2024-03-16-20-58-20-246/function\n",
      "2024-03-16 20:58:29,171 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-evaluate/2024-03-16-20-58-20-246/arguments\n",
      "2024-03-16 20:58:29,269 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp8f3gekyt/requirements.txt'\n",
      "2024-03-16 20:58:29,295 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-evaluate/2024-03-16-20-58-20-246/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:58:32,483 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-preprocess/2024-03-16-20-58-20-246/function\n",
      "2024-03-16 20:58:32,544 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-preprocess/2024-03-16-20-58-20-246/arguments\n",
      "2024-03-16 20:58:32,635 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp8lp6cl1r/requirements.txt'\n",
      "2024-03-16 20:58:32,681 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-14-21-18-decorator/from-idea-to-prod-preprocess/2024-03-16-20-58-20-246/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-14-21-18-decorator',\n",
       " 'ResponseMetadata': {'RequestId': '31825e37-e15f-4878-a9bd-5a6758bde027',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '31825e37-e15f-4878-a9bd-5a6758bde027',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '116',\n",
       "   'date': 'Sat, 16 Mar 2024 20:58:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsert operation serialize the function code, arguments, and other artefacts to S3 where it can be accessed during pipeline's runtime\n",
    "pipeline_decorator.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "92b84443-b4f4-4f89-8fbb-e813e9b9997b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution_decorator = pipeline_decorator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c501c9-02ba-4910-a42f-1a2398b401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_decorator.describe()\n",
    "execution_decorator.wait()\n",
    "execution_decorator.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86481084-68cf-4804-a76a-ab5b078f22e4",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "Be aware of the specific [limitations](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-step-decorator-limit.html) when you use `@step` decorator for pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e4252-719c-4cde-b88f-6eb1b729a955",
   "metadata": {},
   "source": [
    "## Add Feature Store\n",
    "In this section you use SageMaker Feature Store to manage features and dataset for model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cc1d68f4-4bd2-44e7-8dbd-742e05152760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.inputs import TableFormatEnum\n",
    "from sagemaker.feature_store.feature_processor import CSVDataSource, feature_processor, to_pipeline\n",
    "from sagemaker.remote_function import remote\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timezone, date\n",
    "from time import gmtime, strftime, sleep\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "46fe3378-740f-4e46-98fd-490ef17d1834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "63a84977-e63c-4fd6-a643-2bc2d039229b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "project = \"from-idea-to-prod\"\n",
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d62fd49-01ac-41bb-b3ea-6b640e509188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'feature_store_bucket_prefix' (str)\n"
     ]
    }
   ],
   "source": [
    "feature_store_bucket_prefix = 'from-idea-to-prod/feature-store'\n",
    "%store feature_store_bucket_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e101dd-d211-4389-9c8d-61f9513110fe",
   "metadata": {},
   "source": [
    "### Transform raw data into training-ready features\n",
    "First transform raw data into features in order to be able to extract feature group schema based on the transformed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f41c8373-3b55-4c75-94d5-7b48f50ac56e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y       no      no   no   \n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon       261         1    999         0   \n",
       "1      telephone   may         mon       149         1    999         0   \n",
       "2      telephone   may         mon       226         1    999         0   \n",
       "3      telephone   may         mon       151         1    999         0   \n",
       "4      telephone   may         mon       307         1    999         0   \n",
       "...          ...   ...         ...       ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri       334         1    999         0   \n",
       "41184   cellular   nov         fri       383         1    999         0   \n",
       "41185   cellular   nov         fri       189         2    999         0   \n",
       "41186   cellular   nov         fri       442         1    999         0   \n",
       "41187   cellular   nov         fri       239         3    999         1   \n",
       "\n",
       "          poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "1      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "...            ...           ...             ...            ...        ...   \n",
       "41183  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41187      failure          -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed    y  \n",
       "0           5191.0   no  \n",
       "1           5191.0   no  \n",
       "2           5191.0   no  \n",
       "3           5191.0   no  \n",
       "4           5191.0   no  \n",
       "...            ...  ...  \n",
       "41183       4963.6  yes  \n",
       "41184       4963.6   no  \n",
       "41185       4963.6   no  \n",
       "41186       4963.6  yes  \n",
       "41187       4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(dataset_file_local_path, sep=\";\")\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f39290b0-12ef-4c96-9c76-cfb68671e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"y\"\n",
    "\n",
    "# Indicator variable to capture when pdays takes a value of 999\n",
    "df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "# Indicator for individuals not actively employed\n",
    "df_data[\"not_working\"] = np.where(\n",
    "    np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    ")\n",
    "\n",
    "# remove unnecessary data\n",
    "df_model_data = df_data.drop(\n",
    "    [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "bins = [18, 30, 40, 50, 60, 70, 90]\n",
    "labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70-plus']\n",
    "\n",
    "df_model_data['age_range'] = pd.cut(df_model_data.age, bins, labels=labels, include_lowest=True)\n",
    "df_model_data = pd.concat([df_model_data, pd.get_dummies(df_model_data['age_range'], prefix='age', dtype=int)], axis=1)\n",
    "df_model_data.drop('age', axis=1, inplace=True)\n",
    "df_model_data.drop('age_range', axis=1, inplace=True)\n",
    "\n",
    "scaled_features = ['pdays', 'previous', 'campaign']\n",
    "df_model_data[scaled_features] = MinMaxScaler().fit_transform(df_model_data[scaled_features])\n",
    "\n",
    "df_model_data = pd.get_dummies(df_model_data, dtype=int)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "# Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "df_model_data = pd.concat(\n",
    "    [\n",
    "        df_model_data[\"y_yes\"].rename(target_col),\n",
    "        df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fed45a86-8f00-4e1b-a2c7-acec0fe622e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_event_timestamp():\n",
    "    # naive datetime representing local time\n",
    "    naive_dt = datetime.now()\n",
    "    # take timezone into account\n",
    "    aware_dt = naive_dt.astimezone()\n",
    "    # time in UTC\n",
    "    utc_dt = aware_dt.astimezone(timezone.utc)\n",
    "    # transform to ISO-8601 format\n",
    "    event_time = utc_dt.isoformat(timespec='milliseconds')\n",
    "    event_time = event_time.replace('+00:00', 'Z')\n",
    "    return event_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d29a2-8b82-4961-bbf0-4b655abb8101",
   "metadata": {},
   "source": [
    "Add `event_time` and `record_id` columns to the dataset as these two fields are required for each feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ca22a358-de8e-4ac5-b036-54f35ec20cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_model_data['event_time'] = generate_event_timestamp()\n",
    "df_model_data['record_id'] = [f'R{i}' for i in range(len(df_model_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9181d-aa22-42af-b9fd-d057d8b24cd1",
   "metadata": {},
   "source": [
    "Feature names cannot contain '.' and cannot end on '_'. Also remove '-' from the column names when converting column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8b9b4220-e3e6-4abe-a193-5b9bb5030a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_col_name(c):\n",
    "    return c.replace('.', '_').replace('-', '_').rstrip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6d233973-f8d3-488f-9f92-44cbb5f34382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_model_data = df_model_data.rename(columns=convert_col_name)\n",
    "df_model_data = df_model_data.convert_dtypes(infer_objects=True, convert_boolean=False)\n",
    "df_model_data['record_id'] = df_model_data['record_id'].astype('string')\n",
    "df_model_data['event_time'] = df_model_data['event_time'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4ef70777-a343-487a-b087-b220734acbe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y                                Int64\n",
       "campaign                       Float64\n",
       "pdays                          Float64\n",
       "previous                       Float64\n",
       "no_previous_contact              Int64\n",
       "                             ...      \n",
       "poutcome_failure                 Int64\n",
       "poutcome_nonexistent             Int64\n",
       "poutcome_success                 Int64\n",
       "event_time              string[python]\n",
       "record_id               string[python]\n",
       "Length: 67, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "958e8afb-9761-4624-b4eb-72b9d5a6be3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'campaign', 'pdays', 'previous', 'no_previous_contact',\n",
       "       'not_working', 'age_18_29', 'age_30_39', 'age_40_49', 'age_50_59',\n",
       "       'age_60_69', 'age_70_plus', 'job_admin', 'job_blue_collar',\n",
       "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
       "       'job_self_employed', 'job_services', 'job_student', 'job_technician',\n",
       "       'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married',\n",
       "       'marital_single', 'marital_unknown', 'education_basic_4y',\n",
       "       'education_basic_6y', 'education_basic_9y', 'education_high_school',\n",
       "       'education_illiterate', 'education_professional_course',\n",
       "       'education_university_degree', 'education_unknown', 'default_no',\n",
       "       'default_unknown', 'default_yes', 'housing_no', 'housing_unknown',\n",
       "       'housing_yes', 'loan_no', 'loan_unknown', 'loan_yes',\n",
       "       'contact_cellular', 'contact_telephone', 'month_apr', 'month_aug',\n",
       "       'month_dec', 'month_jul', 'month_jun', 'month_mar', 'month_may',\n",
       "       'month_nov', 'month_oct', 'month_sep', 'day_of_week_fri',\n",
       "       'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue',\n",
       "       'day_of_week_wed', 'poutcome_failure', 'poutcome_nonexistent',\n",
       "       'poutcome_success', 'event_time', 'record_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a388370e-4596-4968-8358-c26d9a44d03a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>age_18_29</th>\n",
       "      <th>age_30_39</th>\n",
       "      <th>age_40_49</th>\n",
       "      <th>age_50_59</th>\n",
       "      <th>age_60_69</th>\n",
       "      <th>age_70_plus</th>\n",
       "      <th>job_admin</th>\n",
       "      <th>job_blue_collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self_employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>education_basic_4y</th>\n",
       "      <th>education_basic_6y</th>\n",
       "      <th>education_basic_9y</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional_course</th>\n",
       "      <th>education_university_degree</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>event_time</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:15:41.091Z</td>\n",
       "      <td>R0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:15:41.091Z</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:15:41.091Z</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:15:41.091Z</td>\n",
       "      <td>R3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:15:41.091Z</td>\n",
       "      <td>R4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  campaign  pdays  previous  no_previous_contact  not_working  age_18_29  \\\n",
       "0  0       0.0    1.0       0.0                    1            0          0   \n",
       "1  0       0.0    1.0       0.0                    1            0          0   \n",
       "2  0       0.0    1.0       0.0                    1            0          0   \n",
       "3  0       0.0    1.0       0.0                    1            0          0   \n",
       "4  0       0.0    1.0       0.0                    1            0          0   \n",
       "\n",
       "   age_30_39  age_40_49  age_50_59  age_60_69  age_70_plus  job_admin  \\\n",
       "0          0          0          1          0            0          0   \n",
       "1          0          0          1          0            0          0   \n",
       "2          1          0          0          0            0          0   \n",
       "3          1          0          0          0            0          1   \n",
       "4          0          0          1          0            0          0   \n",
       "\n",
       "   job_blue_collar  job_entrepreneur  job_housemaid  job_management  \\\n",
       "0                0                 0              1               0   \n",
       "1                0                 0              0               0   \n",
       "2                0                 0              0               0   \n",
       "3                0                 0              0               0   \n",
       "4                0                 0              0               0   \n",
       "\n",
       "   job_retired  job_self_employed  job_services  job_student  job_technician  \\\n",
       "0            0                  0             0            0               0   \n",
       "1            0                  0             1            0               0   \n",
       "2            0                  0             1            0               0   \n",
       "3            0                  0             0            0               0   \n",
       "4            0                  0             1            0               0   \n",
       "\n",
       "   job_unemployed  job_unknown  marital_divorced  marital_married  \\\n",
       "0               0            0                 0                1   \n",
       "1               0            0                 0                1   \n",
       "2               0            0                 0                1   \n",
       "3               0            0                 0                1   \n",
       "4               0            0                 0                1   \n",
       "\n",
       "   marital_single  marital_unknown  education_basic_4y  education_basic_6y  \\\n",
       "0               0                0                   1                   0   \n",
       "1               0                0                   0                   0   \n",
       "2               0                0                   0                   0   \n",
       "3               0                0                   0                   1   \n",
       "4               0                0                   0                   0   \n",
       "\n",
       "   education_basic_9y  education_high_school  education_illiterate  \\\n",
       "0                   0                      0                     0   \n",
       "1                   0                      1                     0   \n",
       "2                   0                      1                     0   \n",
       "3                   0                      0                     0   \n",
       "4                   0                      1                     0   \n",
       "\n",
       "   education_professional_course  education_university_degree  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   education_unknown  default_no  default_unknown  default_yes  housing_no  \\\n",
       "0                  0           1                0            0           1   \n",
       "1                  0           0                1            0           1   \n",
       "2                  0           1                0            0           0   \n",
       "3                  0           1                0            0           1   \n",
       "4                  0           1                0            0           1   \n",
       "\n",
       "   housing_unknown  housing_yes  loan_no  loan_unknown  loan_yes  \\\n",
       "0                0            0        1             0         0   \n",
       "1                0            0        1             0         0   \n",
       "2                0            1        1             0         0   \n",
       "3                0            0        1             0         0   \n",
       "4                0            0        0             0         1   \n",
       "\n",
       "   contact_cellular  contact_telephone  month_apr  month_aug  month_dec  \\\n",
       "0                 0                  1          0          0          0   \n",
       "1                 0                  1          0          0          0   \n",
       "2                 0                  1          0          0          0   \n",
       "3                 0                  1          0          0          0   \n",
       "4                 0                  1          0          0          0   \n",
       "\n",
       "   month_jul  month_jun  month_mar  month_may  month_nov  month_oct  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          1          0          0   \n",
       "2          0          0          0          1          0          0   \n",
       "3          0          0          0          1          0          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0                0                1                0   \n",
       "1          0                0                1                0   \n",
       "2          0                0                1                0   \n",
       "3          0                0                1                0   \n",
       "4          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  poutcome_failure  poutcome_nonexistent  \\\n",
       "0                0                0                 0                     1   \n",
       "1                0                0                 0                     1   \n",
       "2                0                0                 0                     1   \n",
       "3                0                0                 0                     1   \n",
       "4                0                0                 0                     1   \n",
       "\n",
       "   poutcome_success                event_time record_id  \n",
       "0                 0  2024-03-11T15:15:41.091Z        R0  \n",
       "1                 0  2024-03-11T15:15:41.091Z        R1  \n",
       "2                 0  2024-03-11T15:15:41.091Z        R2  \n",
       "3                 0  2024-03-11T15:15:41.091Z        R3  \n",
       "4                 0  2024-03-11T15:15:41.091Z        R4  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "cecd4de7-8d8f-4b1d-b16b-671a33cedfd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 67)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6602ddca-cb2b-4381-bac5-ac653a2adac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_model_data.to_csv('./data/feature_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "de5dddb9-467c-4ff3-8903-c782ae0a94ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record_count = len(df_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "20e5fbc1-3ee0-4e76-a3f1-1e3fdf9aed85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41188"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15454a42-b7f1-4bf8-8fb5-71358819cf23",
   "metadata": {},
   "source": [
    "### Create a feature group\n",
    "Now is everything ready to create a feature group with the dataset schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "900eb526-ea42-4a09-85c4-883c6d6d6ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_feature_group_name = f'{project}-{current_timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ce75080b-c1c8-477c-8b07-76350de12ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dataset_feature_group_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store dataset_feature_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "791d46f8-f7dd-4799-b66d-c08f82b4b2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_feature_group = FeatureGroup(name=dataset_feature_group_name, sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b09632-0ca0-4186-94f8-04d373926030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the DataFrame to extract the feature group definitions\n",
    "dataset_feature_group.load_feature_definitions(data_frame=df_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "453b4a61-4605-4618-a471-2c46298aa9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    print(f'Initial status: {status}')\n",
    "    while status == 'Creating':\n",
    "        print(f'Waiting for feature group: {feature_group.name} to be created ...')\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    if status != 'Created':\n",
    "        raise SystemExit(f'Failed to create feature group {feature_group.name}: {status}')\n",
    "    print(f'FeatureGroup {feature_group.name} was successfully created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "573280f8-6a7f-430e-a037-162db0d80694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:906545278380:feature-group/from-idea-to-prod-03-11-15-15',\n",
       " 'ResponseMetadata': {'RequestId': 'a4b19b62-0ba3-44db-8f6c-e4348d49883a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a4b19b62-0ba3-44db-8f6c-e4348d49883a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '106',\n",
       "   'date': 'Mon, 11 Mar 2024 15:17:45 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_feature_group.create(\n",
    "    s3_uri=f's3://{bucket_name}/{feature_store_bucket_prefix}', \n",
    "    record_identifier_name='record_id', \n",
    "    event_time_feature_name='event_time', \n",
    "    role_arn=sm_role, \n",
    "    enable_online_store=False,\n",
    "    table_format=TableFormatEnum.ICEBERG \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baa4ac82-e982-4f74-917c-25b78292a587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial status: Creating\n",
      "Waiting for feature group: from-idea-to-prod-03-11-09-47 to be created ...\n",
      "Waiting for feature group: from-idea-to-prod-03-11-09-47 to be created ...\n",
      "Waiting for feature group: from-idea-to-prod-03-11-09-47 to be created ...\n",
      "Waiting for feature group: from-idea-to-prod-03-11-09-47 to be created ...\n",
      "Waiting for feature group: from-idea-to-prod-03-11-09-47 to be created ...\n",
      "FeatureGroup from-idea-to-prod-03-11-09-47 was successfully created.\n"
     ]
    }
   ],
   "source": [
    "wait_for_feature_group_creation_complete(dataset_feature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "64184cff-44ed-49a4-8364-ffc755e6b01c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:906545278380:feature-group/from-idea-to-prod-03-11-15-15',\n",
       " 'FeatureGroupName': 'from-idea-to-prod-03-11-15-15',\n",
       " 'RecordIdentifierFeatureName': 'record_id',\n",
       " 'EventTimeFeatureName': 'event_time',\n",
       " 'FeatureDefinitions': [{'FeatureName': 'y', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'campaign', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'pdays', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'previous', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'no_previous_contact', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'not_working', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_18_29', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_30_39', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_40_49', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_50_59', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_60_69', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'age_70_plus', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_admin', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_blue_collar', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_entrepreneur', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_housemaid', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_management', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_retired', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_self_employed', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_services', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_student', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_technician', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_unemployed', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'job_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'marital_divorced', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'marital_married', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'marital_single', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'marital_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_basic_4y', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_basic_6y', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_basic_9y', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_high_school', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_illiterate', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_professional_course', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_university_degree', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'education_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'default_no', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'default_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'default_yes', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'housing_no', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'housing_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'housing_yes', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'loan_no', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'loan_unknown', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'loan_yes', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'contact_cellular', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'contact_telephone', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_apr', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_aug', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_dec', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_jul', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_jun', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_mar', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_may', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_nov', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_oct', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'month_sep', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'day_of_week_fri', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'day_of_week_mon', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'day_of_week_thu', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'day_of_week_tue', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'day_of_week_wed', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'poutcome_failure', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'poutcome_nonexistent', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'poutcome_success', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'event_time', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'record_id', 'FeatureType': 'String'}],\n",
       " 'CreationTime': datetime.datetime(2024, 3, 11, 15, 17, 45, 530000, tzinfo=tzlocal()),\n",
       " 'OfflineStoreConfig': {'S3StorageConfig': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/feature-store',\n",
       "   'ResolvedOutputS3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/feature-store/906545278380/sagemaker/us-east-1/offline-store/from-idea-to-prod-03-11-15-15-1710170265/data'},\n",
       "  'DisableGlueTableCreation': False,\n",
       "  'DataCatalogConfig': {'TableName': 'from_idea_to_prod_03_11_15_15_1710170265',\n",
       "   'Catalog': 'AwsDataCatalog',\n",
       "   'Database': 'SageMaker_FeatureStore'},\n",
       "  'TableFormat': 'Iceberg'},\n",
       " 'RoleArn': 'arn:aws:iam::906545278380:role/sm-domain-workshop-SageMakerExecutionRole-2tKGP8Kthe7Q',\n",
       " 'FeatureGroupStatus': 'Created',\n",
       " 'ResponseMetadata': {'RequestId': '547f2a23-f02f-4635-8d06-9a583da12763',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '547f2a23-f02f-4635-8d06-9a583da12763',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '5174',\n",
       "   'date': 'Mon, 11 Mar 2024 15:19:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_feature_group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383fb27-7132-4439-bab4-b805be36d3c7",
   "metadata": {},
   "source": [
    "The feature group is ready for use. Now you need to ingest data into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26346cd4-47fe-4129-ac28-de16a30175fb",
   "metadata": {},
   "source": [
    "### Ingest data into the feature group\n",
    "Same as in the previous section you're going to use [`@step`](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-step-decorator-create-pipeline.html) decorator to create a feature ingestion pipeline. You can use a SageMaker pipeline to process and ingest features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d919d20a-7cd3-40e6-8ab5-093f6f59f72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a requirements.txt file with dependencies for the pipeline step\n",
    "sagemaker_version = sagemaker.__version__\n",
    "with open(\"requirements.txt\", \"w\") as file:\n",
    "    file.write(f\"sagemaker=={sagemaker_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b5a47-c151-4ca8-8370-7466f0394cd2",
   "metadata": {},
   "source": [
    "Compile all previous feature transformation and ingestion code into a remote function. You use the Python SDK [`FeatureGroup.ingest()`](https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html#sagemaker.feature_store.feature_group.FeatureGroup.ingest) method to ingest the content of a pandas DataFrame to a feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9cef1bb5-eae3-4066-b0f1-8968ba795ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@step(name=f'{project}-fs-ingest')\n",
    "def process_and_ingest(\n",
    "    input_s3_url,\n",
    "    feature_group_name,\n",
    "):\n",
    "    from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "    from sagemaker.s3_utils import parse_s3_url\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from datetime import datetime, timezone, date\n",
    "    import boto3\n",
    "\n",
    "    def generate_event_timestamp():\n",
    "        # naive datetime representing local time\n",
    "        naive_dt = datetime.now()\n",
    "        # take timezone into account\n",
    "        aware_dt = naive_dt.astimezone()\n",
    "        # time in UTC\n",
    "        utc_dt = aware_dt.astimezone(timezone.utc)\n",
    "        # transform to ISO-8601 format\n",
    "        event_time = utc_dt.isoformat(timespec='milliseconds')\n",
    "        event_time = event_time.replace('+00:00', 'Z')\n",
    "        return event_time\n",
    "    \n",
    "    def convert_col_name(c):\n",
    "        return c.replace('.', '_').replace('-', '_').rstrip('_')\n",
    "    \n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    bucket, object_key = parse_s3_url(input_s3_url)\n",
    "    s3.download_file(bucket, object_key, \"input_data.csv\")\n",
    "    \n",
    "    # Load data\n",
    "    df_data = pd.read_csv(\"input_data.csv\", sep=\";\")\n",
    "    \n",
    "    target_col = \"y\"\n",
    "    \n",
    "    # Indicator variable to capture when pdays takes a value of 999\n",
    "    df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "    # Indicator for individuals not actively employed\n",
    "    df_data[\"not_working\"] = np.where(\n",
    "        np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    # remove unnecessary data\n",
    "    df_model_data = df_data.drop(\n",
    "        [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    bins = [18, 30, 40, 50, 60, 70, 90]\n",
    "    labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70-plus']\n",
    "\n",
    "    df_model_data['age_range'] = pd.cut(df_model_data.age, bins, labels=labels, include_lowest=True)\n",
    "    df_model_data = pd.concat([df_model_data, pd.get_dummies(df_model_data['age_range'], prefix='age', dtype=int)], axis=1)\n",
    "    df_model_data.drop('age', axis=1, inplace=True)\n",
    "    df_model_data.drop('age_range', axis=1, inplace=True)\n",
    "\n",
    "    scaled_features = ['pdays', 'previous', 'campaign']\n",
    "    df_model_data[scaled_features] = MinMaxScaler().fit_transform(df_model_data[scaled_features])\n",
    "\n",
    "    df_model_data = pd.get_dummies(df_model_data, dtype=int)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "    # Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "    df_model_data = pd.concat(\n",
    "        [\n",
    "            df_model_data[\"y_yes\"].rename(target_col),\n",
    "            df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    df_model_data['event_time'] = generate_event_timestamp()\n",
    "    df_model_data['record_id'] = [f'R{i}' for i in range(len(df_model_data))]\n",
    "    \n",
    "    df_model_data = df_model_data.rename(columns=convert_col_name)\n",
    "    \n",
    "    df_model_data = df_model_data.convert_dtypes(infer_objects=True, convert_boolean=False)\n",
    "    df_model_data['record_id'] = df_model_data['record_id'].astype('string')\n",
    "    df_model_data['event_time'] = df_model_data['event_time'].astype('string')\n",
    "    \n",
    "    # Ingest data into the feature group\n",
    "    dataset_feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker.Session())\n",
    "    \n",
    "    print(f'Ingesting data into feature group: {dataset_feature_group.name} ...')\n",
    "    dataset_feature_group.ingest(data_frame=df_model_data, max_processes=4, wait=True)\n",
    "    print(f'{len(df_model_data)} customer records ingested into feature group: {dataset_feature_group.name}')\n",
    "    \n",
    "    return dataset_feature_group.describe()['FeatureGroupArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "be39ac38-52d6-4b92-b26b-f8d5e0491000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create parameters for the feature store ingestion pipeline\n",
    "input_s3_url_param = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=input_s3_url,\n",
    ")\n",
    "\n",
    "feature_group_name_param = ParameterString(\n",
    "    name=\"FeatureGroupName\",\n",
    "    default_value=dataset_feature_group.describe()['FeatureGroupArn'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "518070fc-fdeb-42f2-9f22-586eeef57163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pipeline with an ingest step\n",
    "pipeline_fs_ingest = Pipeline(\n",
    "    name=f\"{pipeline_name}-fs-ingest\",\n",
    "    parameters=[\n",
    "        input_s3_url_param,\n",
    "        feature_group_name_param\n",
    "    ],\n",
    "    steps=[\n",
    "        process_and_ingest(\n",
    "            input_s3_url=input_s3_url_param,\n",
    "            feature_group_name=feature_group_name_param,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "785d6603-9308-4ed7-883d-ac86fb05255d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 15:20:50,896 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-48-054/function\n",
      "2024-03-11 15:20:50,968 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-48-054/arguments\n",
      "2024-03-11 15:20:51,175 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpnedd3b2q/requirements.txt'\n",
      "2024-03-11 15:20:51,204 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-48-054/pre_exec_script_and_dependencies'\n",
      "2024-03-11 15:20:51,587 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmpwdc0cnq6/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-03-11 15:20:54,844 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpwdc0cnq6/workspace.zip'\n",
      "2024-03-11 15:20:55,431 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/sm_rf_user_ws/2024-03-11-15-20-48-054/workspace.zip'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2024-03-11 15:20:55,969 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-55-968/function\n",
      "2024-03-11 15:20:56,066 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-55-968/arguments\n",
      "2024-03-11 15:20:56,379 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpe547p1a9/requirements.txt'\n",
      "2024-03-11 15:20:56,413 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/from-idea-to-prod-fs-ingest/2024-03-11-15-20-55-968/pre_exec_script_and_dependencies'\n",
      "2024-03-11 15:20:56,685 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmp64fubxdy/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-03-11 15:21:00,110 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmp64fubxdy/workspace.zip'\n",
      "2024-03-11 15:21:00,760 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/sm_rf_user_ws/2024-03-11-15-20-55-968/workspace.zip'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest',\n",
       " 'ResponseMetadata': {'RequestId': '61d40a38-e996-4924-9142-86128f7c0d62',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '61d40a38-e996-4924-9142-86128f7c0d62',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '116',\n",
       "   'date': 'Mon, 11 Mar 2024 15:21:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_fs_ingest.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a8e9e71b-2f80-4d81-800b-3fd122a6c9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution_fs_ingest = pipeline_fs_ingest.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "65b16f27-5591-47b3-b7a9-11de8c829ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-11-09-43-fs-ingest/execution/rmlv3gxa4jm7',\n",
       " 'PipelineExecutionDisplayName': 'execution-1710170466576',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'PipelineExperimentConfig': {'ExperimentName': 'from-idea-to-prod-pipeline-03-11-09-43-fs-ingest',\n",
       "  'TrialName': 'rmlv3gxa4jm7'},\n",
       " 'CreationTime': datetime.datetime(2024, 3, 11, 15, 21, 6, 515000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 3, 11, 15, 21, 6, 515000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:906545278380:user-profile/d-9oteoq7mqbpp/studio-user-54491630',\n",
       "  'UserProfileName': 'studio-user-54491630',\n",
       "  'DomainId': 'd-9oteoq7mqbpp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::906545278380:assumed-role/sm-domain-workshop-SageMakerExecutionRole-2tKGP8Kthe7Q/SageMaker',\n",
       "   'PrincipalId': 'AROA5GESPFWWPBQG4SGTG:SageMaker'}},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:906545278380:user-profile/d-9oteoq7mqbpp/studio-user-54491630',\n",
       "  'UserProfileName': 'studio-user-54491630',\n",
       "  'DomainId': 'd-9oteoq7mqbpp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::906545278380:assumed-role/sm-domain-workshop-SageMakerExecutionRole-2tKGP8Kthe7Q/SageMaker',\n",
       "   'PrincipalId': 'AROA5GESPFWWPBQG4SGTG:SageMaker'}},\n",
       " 'ResponseMetadata': {'RequestId': '2a4aae87-17b7-473f-8ad3-cba08505a9ab',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2a4aae87-17b7-473f-8ad3-cba08505a9ab',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1291',\n",
       "   'date': 'Mon, 11 Mar 2024 15:21:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_fs_ingest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "01456d7c-8b70-45ae-95fa-223347d238c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'from-idea-to-prod-fs-ingest',\n",
       "  'StartTime': datetime.datetime(2024, 3, 11, 15, 21, 7, 785000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 3, 11, 15, 25, 36, 626000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:906545278380:training-job/pipelines-rmlv3gxa4jm7-from-idea-to-prod-fs-kaaFXpqrqJ'}}}]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_fs_ingest.wait()\n",
    "execution_fs_ingest.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1cba0-e18d-4833-87de-dd24dfe95386",
   "metadata": {},
   "source": [
    "### Retrieve ingested features from the feature group\n",
    "\n",
    "There are many approaches to extract features from the offline feature store. For example, you can use [Amazon Athena query](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-create-a-dataset.html#feature-store-athena-sample-queries) to query and join data stored in the offline store, or you can use [Offline Store Python SDK](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-create-a-dataset.html#feature-store-dataset-python-sdk). You're going to use Python SDK to extract features and create a dataset for the model building pipeline.\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <p style=\" text-align: center; margin: auto;\">Ingestion to the offline store is buffered and it takes up to 15 minutes for data to appear in the feature group. After features are ingested and available in the offline store, you can query them and create datasets for model training and scoring.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e2ce438a-b1bf-47b4-82aa-5ebfb604244b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "output_location = f's3://{bucket_name}/{feature_store_bucket_prefix}/offline-store/query_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "685accaa-3679-4e40-95b1-4263826e108d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_historical_record_count(fg):\n",
    "    fs_query = dataset_feature_group.athena_query()\n",
    "    query_string = f'SELECT COUNT(*) FROM \"' + fs_query.table_name + f'\"'\n",
    "    output_location =  f's3://{bucket_name}/{feature_store_bucket_prefix}/offline-store/query_results/'\n",
    "\n",
    "    fs_query.run(query_string=query_string, output_location=output_location)\n",
    "    fs_query.wait()\n",
    "    fs_df = fs_query.as_dataframe()\n",
    "    \n",
    "    return fs_df.iat[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "295ef2b7-dbb8-4078-aa37-c0c46831a9db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 62514bc6-4ac6-4461-a4a6-3cc5f367c7e0 is being executed.\n",
      "INFO:sagemaker:Query 62514bc6-4ac6-4461-a4a6-3cc5f367c7e0 successfully executed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Waiting for data arrives in offline store ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 20c8dc1b-2f73-4f9f-9857-f531f57e75b6 is being executed.\n",
      "INFO:sagemaker:Query 20c8dc1b-2f73-4f9f-9857-f531f57e75b6 successfully executed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Waiting for data arrives in offline store ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query fb5467c1-9f25-4126-a13c-55c57723cb58 is being executed.\n",
      "INFO:sagemaker:Query fb5467c1-9f25-4126-a13c-55c57723cb58 successfully executed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Waiting for data arrives in offline store ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 79613601-050a-4c8a-a911-fb00b8979265 is being executed.\n",
      "INFO:sagemaker:Query 79613601-050a-4c8a-a911-fb00b8979265 successfully executed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41188 feature records are available in offline store for from-idea-to-prod-03-11-15-15 feature group]\n"
     ]
    }
   ],
   "source": [
    "# Before accessing the feature data you need to check if the offline feature store was populated\n",
    "offline_store_contents = None\n",
    "while offline_store_contents is None:    \n",
    "    fs_record_count = get_historical_record_count(dataset_feature_group)\n",
    "\n",
    "    if fs_record_count >= record_count:\n",
    "        print(f'[{fs_record_count} feature records are available in offline store for {dataset_feature_group.name} feature group]')\n",
    "        offline_store_contents = fs_record_count\n",
    "    else:\n",
    "        print('[Waiting for data arrives in offline store ...]')\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ad7d5-d1fc-4c6b-9dce-fdf8407b05ec",
   "metadata": {},
   "source": [
    "#### Use the Amazon SageMaker Python SDK (DatasetBuilder) to query the feature store\n",
    "This section demonstrates how to use [`DatasetBuilder`](https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html#sagemaker.feature_store.dataset_builder.DatasetBuilder) to get data from feature groups. Refer to the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-create-a-dataset.html) for detailed examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b2c0f0ab-1f41-40e8-9292-02d8a7137694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_store import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "aa8f54a5-7d0a-4a62-875b-1f2a84723eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name=\"sagemaker-featurestore-runtime\",region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6ad74743-b383-4706-bc6c-75b9004beb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create FeatureStore session object\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")\n",
    "\n",
    "feature_store = FeatureStore(sagemaker_session=feature_store_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fe96e430-7370-41d6-acbb-8fd38acda684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_feature_names = [f.feature_name for f in dataset_feature_group.feature_definitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3b9feb8f-8c4d-4621-b558-7d634df694e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataset builder to retrieve the most recent version of each record\n",
    "builder = feature_store.create_dataset(\n",
    "    base=dataset_feature_group,\n",
    "    # included_feature_names=included_feature_names,\n",
    "    output_path=output_location,\n",
    ").with_number_of_recent_records_by_record_identifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6daad11c-4a6b-4c68-b2c4-95d04202ab9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query b98da08f-1832-4f4b-b5d7-e9146ab83b11 is being executed.\n",
      "INFO:sagemaker:Query b98da08f-1832-4f4b-b5d7-e9146ab83b11 successfully executed.\n"
     ]
    }
   ],
   "source": [
    "df_dataset, query = builder.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "2dacb90a-0880-4ba3-9ddd-e0e779e05ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>age_18_29</th>\n",
       "      <th>age_30_39</th>\n",
       "      <th>age_40_49</th>\n",
       "      <th>age_50_59</th>\n",
       "      <th>age_60_69</th>\n",
       "      <th>age_70_plus</th>\n",
       "      <th>job_admin</th>\n",
       "      <th>job_blue_collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self_employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>education_basic_4y</th>\n",
       "      <th>education_basic_6y</th>\n",
       "      <th>education_basic_9y</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional_course</th>\n",
       "      <th>education_university_degree</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>event_time</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R19132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R19358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R40455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R40459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R32456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>0</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R1587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>1</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R11931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R32830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11T15:23:16.272Z</td>\n",
       "      <td>R12149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
       "0      0  0.018182    1.0  0.000000                    1            0   \n",
       "1      0  0.000000    1.0  0.000000                    1            0   \n",
       "2      0  0.036364    1.0  0.000000                    1            0   \n",
       "3      0  0.018182    1.0  0.000000                    1            0   \n",
       "4      0  0.000000    1.0  0.000000                    1            0   \n",
       "...   ..       ...    ...       ...                  ...          ...   \n",
       "41183  0  0.018182    1.0  0.142857                    1            0   \n",
       "41184  0  0.072727    1.0  0.000000                    1            0   \n",
       "41185  1  0.036364    1.0  0.000000                    1            0   \n",
       "41186  1  0.000000    1.0  0.000000                    1            0   \n",
       "41187  0  0.036364    1.0  0.000000                    1            0   \n",
       "\n",
       "       age_18_29  age_30_39  age_40_49  age_50_59  age_60_69  age_70_plus  \\\n",
       "0              0          0          1          0          0            0   \n",
       "1              0          0          0          1          0            0   \n",
       "2              0          0          1          0          0            0   \n",
       "3              0          1          0          0          0            0   \n",
       "4              1          0          0          0          0            0   \n",
       "...          ...        ...        ...        ...        ...          ...   \n",
       "41183          0          1          0          0          0            0   \n",
       "41184          0          0          0          1          0            0   \n",
       "41185          0          0          1          0          0            0   \n",
       "41186          1          0          0          0          0            0   \n",
       "41187          1          0          0          0          0            0   \n",
       "\n",
       "       job_admin  job_blue_collar  job_entrepreneur  job_housemaid  \\\n",
       "0              0                0                 0              0   \n",
       "1              0                1                 0              0   \n",
       "2              0                1                 0              0   \n",
       "3              1                0                 0              0   \n",
       "4              0                0                 0              0   \n",
       "...          ...              ...               ...            ...   \n",
       "41183          0                0                 0              0   \n",
       "41184          0                0                 0              0   \n",
       "41185          0                1                 0              0   \n",
       "41186          0                1                 0              0   \n",
       "41187          0                0                 0              0   \n",
       "\n",
       "       job_management  job_retired  job_self_employed  job_services  \\\n",
       "0                   0            0                  0             0   \n",
       "1                   0            0                  0             0   \n",
       "2                   0            0                  0             0   \n",
       "3                   0            0                  0             0   \n",
       "4                   0            0                  0             0   \n",
       "...               ...          ...                ...           ...   \n",
       "41183               0            0                  0             0   \n",
       "41184               0            0                  0             0   \n",
       "41185               0            0                  0             0   \n",
       "41186               0            0                  0             0   \n",
       "41187               0            0                  1             0   \n",
       "\n",
       "       job_student  job_technician  job_unemployed  job_unknown  \\\n",
       "0                0               1               0            0   \n",
       "1                0               0               0            0   \n",
       "2                0               0               0            0   \n",
       "3                0               0               0            0   \n",
       "4                0               1               0            0   \n",
       "...            ...             ...             ...          ...   \n",
       "41183            0               1               0            0   \n",
       "41184            0               1               0            0   \n",
       "41185            0               0               0            0   \n",
       "41186            0               0               0            0   \n",
       "41187            0               0               0            0   \n",
       "\n",
       "       marital_divorced  marital_married  marital_single  marital_unknown  \\\n",
       "0                     0                1               0                0   \n",
       "1                     0                1               0                0   \n",
       "2                     0                1               0                0   \n",
       "3                     0                0               1                0   \n",
       "4                     0                0               1                0   \n",
       "...                 ...              ...             ...              ...   \n",
       "41183                 0                1               0                0   \n",
       "41184                 0                1               0                0   \n",
       "41185                 0                1               0                0   \n",
       "41186                 0                0               1                0   \n",
       "41187                 0                1               0                0   \n",
       "\n",
       "       education_basic_4y  education_basic_6y  education_basic_9y  \\\n",
       "0                       0                   0                   0   \n",
       "1                       1                   0                   0   \n",
       "2                       0                   0                   1   \n",
       "3                       0                   0                   0   \n",
       "4                       0                   0                   0   \n",
       "...                   ...                 ...                 ...   \n",
       "41183                   0                   0                   0   \n",
       "41184                   0                   0                   0   \n",
       "41185                   0                   0                   1   \n",
       "41186                   0                   0                   1   \n",
       "41187                   0                   0                   0   \n",
       "\n",
       "       education_high_school  education_illiterate  \\\n",
       "0                          0                     0   \n",
       "1                          0                     0   \n",
       "2                          0                     0   \n",
       "3                          1                     0   \n",
       "4                          0                     0   \n",
       "...                      ...                   ...   \n",
       "41183                      0                     0   \n",
       "41184                      0                     0   \n",
       "41185                      0                     0   \n",
       "41186                      0                     0   \n",
       "41187                      0                     0   \n",
       "\n",
       "       education_professional_course  education_university_degree  \\\n",
       "0                                  1                            0   \n",
       "1                                  0                            0   \n",
       "2                                  0                            0   \n",
       "3                                  0                            0   \n",
       "4                                  0                            1   \n",
       "...                              ...                          ...   \n",
       "41183                              1                            0   \n",
       "41184                              0                            1   \n",
       "41185                              0                            0   \n",
       "41186                              0                            0   \n",
       "41187                              0                            1   \n",
       "\n",
       "       education_unknown  default_no  default_unknown  default_yes  \\\n",
       "0                      0           1                0            0   \n",
       "1                      0           1                0            0   \n",
       "2                      0           1                0            0   \n",
       "3                      0           1                0            0   \n",
       "4                      0           1                0            0   \n",
       "...                  ...         ...              ...          ...   \n",
       "41183                  0           1                0            0   \n",
       "41184                  0           0                1            0   \n",
       "41185                  0           0                1            0   \n",
       "41186                  0           1                0            0   \n",
       "41187                  0           1                0            0   \n",
       "\n",
       "       housing_no  housing_unknown  housing_yes  loan_no  loan_unknown  \\\n",
       "0               1                0            0        0             0   \n",
       "1               0                0            1        1             0   \n",
       "2               1                0            0        1             0   \n",
       "3               0                0            1        1             0   \n",
       "4               0                0            1        1             0   \n",
       "...           ...              ...          ...      ...           ...   \n",
       "41183           1                0            0        1             0   \n",
       "41184           0                0            1        1             0   \n",
       "41185           1                0            0        1             0   \n",
       "41186           0                0            1        1             0   \n",
       "41187           1                0            0        1             0   \n",
       "\n",
       "       loan_yes  contact_cellular  contact_telephone  month_apr  month_aug  \\\n",
       "0             1                 1                  0          0          1   \n",
       "1             0                 1                  0          0          1   \n",
       "2             0                 0                  1          0          0   \n",
       "3             0                 1                  0          0          1   \n",
       "4             0                 0                  1          0          1   \n",
       "...         ...               ...                ...        ...        ...   \n",
       "41183         0                 1                  0          0          0   \n",
       "41184         0                 0                  1          0          0   \n",
       "41185         0                 0                  1          0          0   \n",
       "41186         0                 1                  0          0          0   \n",
       "41187         0                 0                  1          0          0   \n",
       "\n",
       "       month_dec  month_jul  month_jun  month_mar  month_may  month_nov  \\\n",
       "0              0          0          0          0          0          0   \n",
       "1              0          0          0          0          0          0   \n",
       "2              0          0          1          0          0          0   \n",
       "3              0          0          0          0          0          0   \n",
       "4              0          0          0          0          0          0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "41183          0          0          0          0          1          0   \n",
       "41184          0          0          0          0          1          0   \n",
       "41185          0          0          1          0          0          0   \n",
       "41186          0          0          0          0          1          0   \n",
       "41187          0          1          0          0          0          0   \n",
       "\n",
       "       month_oct  month_sep  day_of_week_fri  day_of_week_mon  \\\n",
       "0              0          0                0                0   \n",
       "1              0          0                0                0   \n",
       "2              0          0                1                0   \n",
       "3              0          0                0                0   \n",
       "4              0          0                0                0   \n",
       "...          ...        ...              ...              ...   \n",
       "41183          0          0                1                0   \n",
       "41184          0          0                1                0   \n",
       "41185          0          0                1                0   \n",
       "41186          0          0                0                1   \n",
       "41187          0          0                0                0   \n",
       "\n",
       "       day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "0                    0                1                0                 0   \n",
       "1                    0                0                1                 0   \n",
       "2                    0                0                0                 0   \n",
       "3                    0                1                0                 0   \n",
       "4                    0                1                0                 0   \n",
       "...                ...              ...              ...               ...   \n",
       "41183                0                0                0                 1   \n",
       "41184                0                0                0                 0   \n",
       "41185                0                0                0                 0   \n",
       "41186                0                0                0                 0   \n",
       "41187                0                1                0                 0   \n",
       "\n",
       "       poutcome_nonexistent  poutcome_success                event_time  \\\n",
       "0                         1                 0  2024-03-11T15:23:16.272Z   \n",
       "1                         1                 0  2024-03-11T15:23:16.272Z   \n",
       "2                         1                 0  2024-03-11T15:23:16.272Z   \n",
       "3                         1                 0  2024-03-11T15:23:16.272Z   \n",
       "4                         1                 0  2024-03-11T15:23:16.272Z   \n",
       "...                     ...               ...                       ...   \n",
       "41183                     0                 0  2024-03-11T15:23:16.272Z   \n",
       "41184                     1                 0  2024-03-11T15:23:16.272Z   \n",
       "41185                     1                 0  2024-03-11T15:23:16.272Z   \n",
       "41186                     1                 0  2024-03-11T15:23:16.272Z   \n",
       "41187                     1                 0  2024-03-11T15:23:16.272Z   \n",
       "\n",
       "      record_id  \n",
       "0        R19132  \n",
       "1        R19358  \n",
       "2         R9125  \n",
       "3        R40455  \n",
       "4        R40459  \n",
       "...         ...  \n",
       "41183    R32456  \n",
       "41184     R1587  \n",
       "41185    R11931  \n",
       "41186    R32830  \n",
       "41187    R12149  \n",
       "\n",
       "[41188 rows x 67 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77c3d3-881c-47fe-ad90-ddd0eb6ba9e9",
   "metadata": {},
   "source": [
    "### Integrate a feature group in a model building pipeline\n",
    "So far you ingested all transformed features into the feature store. As the last step in this notebook you need to adjust the model building pipeline to use the transformed features from the feature group instead of loading and transforming a raw data file from an S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ff2c7-f979-42d6-ba8e-854ae6b5a24b",
   "metadata": {},
   "source": [
    "Create a new script to extract features and create datasets for training and evaluation steps. There is no feature processing code in the script because all feature engineering is done before ingesting features into feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4dbc58a0-7a11-4387-bc63-7248605ef7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting extract_features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile extract_features.py\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_store import FeatureStore\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--feature_group_name', type=str, default='from-idea-to-prod')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def extract_features(\n",
    "    feature_group_name,\n",
    "):\n",
    "    region = boto3.Session().region_name\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "    featurestore_runtime = boto_session.client(service_name=\"sagemaker-featurestore-runtime\", region_name=region)\n",
    "    \n",
    "    # Create FeatureStore session object\n",
    "    feature_store_session = Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    "    )\n",
    "\n",
    "    output_location = f\"s3://{feature_store_session.default_bucket()}/from-idea-to-prod/feature-store/offline-store/query_results/\"\n",
    "    feature_store = FeatureStore(sagemaker_session=feature_store_session)\n",
    "    dataset_feature_group = FeatureGroup(feature_group_name)\n",
    "    \n",
    "    # Create dataset builder to retrieve the most recent version of each record\n",
    "    builder = feature_store.create_dataset(\n",
    "        base=dataset_feature_group,\n",
    "        output_path=output_location,\n",
    "    ).with_number_of_recent_records_by_record_identifier(1)\n",
    "    \n",
    "    df_dataset, query = builder.to_dataframe()\n",
    "    \n",
    "    return df_dataset\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = 'y'\n",
    "    feature_store_col = ['event_time', 'record_id']\n",
    "    \n",
    "    df_model_data = extract_features(args.feature_group_name).drop(feature_store_col, axis=1)\n",
    "    \n",
    "    print(f\"Extracted {len(df_model_data)} rows from the feature group {args.feature_group_name}\")\n",
    "    \n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df_model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "    \n",
    "     # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "    \n",
    "    #Â Save the baseline dataset for model monitoring\n",
    "    df_model_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=False, header=False)\n",
    "    \n",
    "    print(\"Created datasets. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b4679-bd43-45bc-bbe3-00eac63d42fc",
   "metadata": {},
   "source": [
    "#### Adjust the existing model building pipeline\n",
    "\n",
    "You need to replace the `preproccess` step with a new `extract` step in the pipeline. Look at the pipeline graph and step dependencies:\n",
    "\n",
    "![](img/pipeline-graph-dependencies.png)\n",
    "\n",
    "There are two other steps depending on the `preprocess` â€“ `train` and `evaluate`. You need to replace all references to the `preprocess` step in the input parameters for all the dependent steps with the `extract` step.\n",
    "Since the `train` and `evaluate` steps are changed, all their dependend steps must be re-defined as well. In this pipeline, the `register` step depends on the `train` step and the conditional step depends on `evaluate`.\n",
    "\n",
    "The follow code creates a new `extract` step, re-defines all dependend steps with new references, and upserts the adjusted pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "2bd8d2f6-3024-4802-9363-7fe6886a78a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e6342dfd-6855-482c-925e-a5c71de9b676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_image_uri = boto3.client('sagemaker').describe_training_job(\n",
    "    TrainingJobName=execution_fs_ingest.list_steps()[0]['Metadata']['TrainingJob']['Arn'].split('/')[1]\n",
    ")['AlgorithmSpecification']['TrainingImage']\n",
    "\n",
    "env = {'AWS_DEFAULT_REGION':boto3.Session().region_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "07501991-28de-4f19-b8bc-c9f02fe43731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'script_image_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store script_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "c4448677-0dc7-4109-854a-2066c419adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use script processor with the same ECR image as feature ingestion script\n",
    "extract_processor = ScriptProcessor(\n",
    "        image_uri=script_image_uri,\n",
    "        role=sm_role,\n",
    "        command=[\"python3\"],\n",
    "        instance_type=process_instance_type_param,\n",
    "        instance_count=process_instance_count,\n",
    "        base_job_name=f\"{pipeline_name}-extract\",\n",
    "        sagemaker_session=pipeline_session,\n",
    "        env=env,\n",
    "    )\n",
    "\n",
    "# re-use the feature_group_name_param pipeline parameter \n",
    "processor_args = extract_processor.run(\n",
    "    code='extract_features.py',\n",
    "    outputs=processing_outputs,\n",
    "    arguments = ['--feature_group_name', feature_group_name_param],\n",
    ")\n",
    "    \n",
    "# Define feature extraction step\n",
    "step_extract = ProcessingStep(\n",
    "    name=f\"{project}-extract\",\n",
    "    step_args=processor_args,\n",
    ")\n",
    "\n",
    "# Change references in training_inputs from step_process to step_extract\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=step_extract.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"train_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=step_extract.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"validation_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_args = estimator.fit(training_inputs)\n",
    "\n",
    "# Re-define training step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{project}-train\",\n",
    "    step_args=training_args\n",
    ")\n",
    "\n",
    "# Change references in eval_input for evaluation step from step_process to step_extract\n",
    "eval_inputs=[\n",
    "    ProcessingInput(source=step_train.properties.ModelArtifacts.S3ModelArtifacts, \n",
    "                    destination=\"/opt/ml/processing/model\"),\n",
    "    ProcessingInput(source=step_extract.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri, \n",
    "                    destination=\"/opt/ml/processing/test\"),\n",
    "]\n",
    "\n",
    "eval_args = script_processor.run(\n",
    "    inputs=eval_inputs,\n",
    "    outputs=eval_outputs,\n",
    "    code=\"evaluation.py\",\n",
    ")\n",
    "\n",
    "# Re-define evaluation step\n",
    "step_eval = ProcessingStep(\n",
    "    name=f\"{project}-evaluate\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# Create a model object\n",
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "    \n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name_param,\n",
    "    approval_status=model_approval_status_param,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Re-define register step\n",
    "step_register = ModelStep(\n",
    "    name=f\"{pipeline_name}-register\",\n",
    "    step_args=register_args\n",
    ")\n",
    "\n",
    "# Remove transform step from the pipeline\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{project}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "77914bd2-8453-4139-bdc4-c682ac396e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_def_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "pipeline_feature_store = Pipeline(\n",
    "    name=f\"{pipeline_name}-feature-store\",\n",
    "    parameters=[\n",
    "        feature_group_name_param,\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        model_package_group_name_param,\n",
    "    ],\n",
    "    steps=[step_extract, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=pipeline_session,\n",
    "    pipeline_definition_config=pipeline_def_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "9325112e-e082-4314-921b-6c2503fd7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:906545278380:pipeline/from-idea-to-prod-pipeline-03-14-21-18-feature-store',\n",
       " 'ResponseMetadata': {'RequestId': '2b66f32c-7359-4cb0-8dae-52ec0c368669',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2b66f32c-7359-4cb0-8dae-52ec0c368669',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '120',\n",
       "   'date': 'Sat, 16 Mar 2024 21:28:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_feature_store.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "c1671385-c408-4915-bf63-87407c8b066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_definition = json.loads(pipeline_feature_store.describe()['PipelineDefinition'])\n",
    "# pipeline_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "485178a6-97bd-4021-b4e3-5ca8b982d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_feature_store = pipeline_feature_store.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e128548e-1ff0-4adb-a7b2-8d8e8b275e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these two lines if you'd like to wait until execution is done\n",
    "# execution_fs_ingest.wait()\n",
    "# execution_fs_ingest.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da456c67-e0bc-441c-8f04-5e55bd1ac5d5",
   "metadata": {},
   "source": [
    "### Further reading: use Feature Processor for feature transformation and ingestion\n",
    "SageMaker provides you with a Spark-based [Feature Processor SDK](https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html#feature-processor-decorator) with which you can transform and ingest data from batch data sources into your feature groups. Read through the description and examples in the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-feature-processing.html).\n",
    "\n",
    "Refer to a more detailed example of feature processor in [feature store feature processor](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-featurestore/feature_store_feature_processor.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749da96-9b82-465c-8328-eecd515d23a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1eb4e6-6010-49c3-ada7-9935bf8644b8",
   "metadata": {},
   "source": [
    "## Continue with the workshop flow\n",
    "After finishing this lab, you can continue with the step 4 and 5 [notebooks](04-sagemaker-project.ipynb) or go directly to the step 6 [notebook](06-monitoring.ipynb):\n",
    "\n",
    "- **Step 4 and 5 notebooks**: Use SageMaker Projects to implement CI/CD automation pipelines for model build and deployment\n",
    "\n",
    "- **Step 6 notebooks**: Data and model quality monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9dea1-ec92-4a28-8523-31c990c274a4",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add [data quality check](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and [model explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-clarify-check) steps. Add model metrics calculated by [SageMaker Clarify](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html) to the model metadata in the model registry\n",
    "- Add event-driven launching of the ML pipeline as soon as a new dataset is uploaded to an Amazon S3 bucket. You can use [Amazon EventBridge integeration](https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html#pipeline-eventbridge-schedule) to implement various event-driven workflows\n",
    "- Use a designated IAM execution role for the pipeline execution\n",
    "- Add data encryption by using S3 bucket encryption and AWS KMS keys for container EBS volume encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f9efc-0920-4077-bd58-9f5514550412",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Automate Machine Learning Workflows](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-mlops-automate-ml-workflows/)\n",
    "- [Amazon SageMaker Feature Store workshop](https://github.com/aws-samples/amazon-sagemaker-feature-store-end-to-end-workshop)\n",
    "- [Amazon SageMaker Model Building Pipeline](https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst)\n",
    "- [MLOPs With SageMaker Pipelines Step Decorator](https://towardsaws.com/mlops-with-sagemaker-pipelines-step-decorator-bb63fce88846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874abcd0-2241-4118-9191-011215b861cd",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bfea5-a835-4adc-81f0-e5355bf53a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc7baf-75d2-43fc-9c23-aadb29b72047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
